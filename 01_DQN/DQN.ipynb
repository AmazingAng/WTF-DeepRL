{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WTF 深度强化学习教程 1. Deep Q-Network\n",
        "\n",
        "WTF 深度强化学习教程，帮助新人快速入门 Deep RL，算法使用pytorch 2.0版本实现。\n",
        "\n",
        "**推特**：[@WTFAcademy_](https://twitter.com/WTFAcademy_) ｜ [@0xAA_Science](https://twitter.com/0xAA_Science)\n",
        "\n",
        "**WTF Academy 社群：** [官网 wtf.academy](https://wtf.academy/) | [WTF Solidity 教程](https://github.com/AmazingAng/WTFSolidity) | [discord](https://discord.wtf.academy/) | [微信群申请](https://docs.google.com/forms/d/e/1FAIpQLSe4KGT8Sh6sJ7hedQRuIYirOoZK_85miz3dw7vA1-YjodgJ-A/viewform?usp=sf_link)\n",
        "\n",
        "所有代码和教程开源在 github: [github.com/AmazingAng/WTF-DeepRL](https://github.com/WTFAcademy/WTF-DeepRL)\n",
        "\n",
        "---\n",
        "\n",
        "这一讲，我们将尝试利用pytorch实现深度强化学习的开山之作 Deep Q-Network，DQN，推荐你先阅读 [DQN 论文](https://arxiv.org/abs/1312.5602)。\n",
        "\n",
        "## 0. 先修课程\n",
        "\n",
        "在开始之前，你需要先完成先修课程：\n",
        "\n",
        "1. 强化学习理论：推荐 Sutton 和 Barto 写的[强化学习圣经](http://incompleteideas.net/book/RLbook2020.pdf)。\n",
        "\n",
        "    ![](./img/1-1.png)\n",
        "\n",
        "2. 机器学习：你可以在网上找到很多机器学习的公开课，比如coursera上Andrew Ng的课程。\n",
        "\n",
        "3. python编程：网上你可以找到很多的python入门公开课，我推荐哈佛大学的CS50 python版。\n",
        "\n",
        "## 1. 深度强化学习中的元素\n",
        "\n",
        "强化学习研究的是智能体（Agent）和环境（Environment）交互中如何学习最优策略，以获得最大收益（Cumulative rewards）。Agent需要能够观察环境(observe)的到所处的状态，评判（value）状态下每个动作的价值，选出最优的动作（act）来和环境交互，同时通过从经验中学习不断改善自己的策略（learn from experience）。因此，observe，value，act和learn是强化学习Agent必不可少的元素。\n",
        "\n",
        "![](./img/1-2.png)\n",
        "\n",
        "如果我们给Agent写一个类，大体会长这样的：\n",
        "\n",
        "```python\n",
        "class Agent: \n",
        "\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    def observe(self, observation):\n",
        "        ...\n",
        "        return state\n",
        "\n",
        "    def value(self, state,):\n",
        "        ...\n",
        "        return value_of_actions\n",
        "    \n",
        "    def act(value_of_actions):\n",
        "        ...\n",
        "        return selected_action\n",
        "    \n",
        "    def learn_from_experience(self, batch_size):\n",
        "        ...\n",
        "```\n",
        "\n",
        "这个教程中，我们会使用经典的Atari游戏来训练强化学习算法，下面我们探讨一下这几个函数在Atari环境中起到什么作用：\n",
        "\n",
        "- `observe`: 在Atari中，环境每一步给出的observation（84x84x1的array）可以直接作为state。那么observe()函数只需要把numpy array转换为torch tensor，方便模型后续使用就好了。在更复杂的partial observable环境，我们需要利用observation来推断所处的state，这时observe()函数会由更多功能。\n",
        "- `value`: 在DQN中，`value`函数主要是给出当前state下每个action的Q value，帮助智能体选择最优策略。\n",
        "- `act`: 在DQN中，根据`value`函数给出的Q值，采用epsilon greedy policy选出action。\n",
        "- `learn_from_experience`: 根据收集的经验计算TD Loss（temporal-difference loss），再通过梯度下降算法更新深度神经网络的参数，改善策略。其中TD Loss由Bellman Equation给出：\n",
        "\n",
        "    $$Loss_{TD}=R_t+\\gamma Q(s_{t+1},a_{t+1})−Q(s_t,a_t)$$\n",
        "\n",
        "下面，我们开始完成DQN算法。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 引入包\n",
        "你需要安装相应的包，然后在 jupyter notebook 中导入他们，如果你使用的是Google Colab Research，则需要安装`gym[atari]`和`autorom[accept-rom-license]`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yy1WnM9NroP",
        "outputId": "c6789b55-af8d-443e-ae3f-ad61d485f163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5 (from gym[atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.12.0)\n",
            "Installing collected packages: ale-py\n",
            "Successfully installed ale-py-0.7.5\n",
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]) (8.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]) (2.27.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (3.4)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=69b44dc7b1b1aad6cb9ea5a7645a7e43a5bca71ceea9b759f5e4a94cb5f9cbb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
            "/usr/local/lib/python3.10/dist-packages/jaxlib/xla_client.py:225: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
            "  float8_e4m3b11fnuz = ml_dtypes.float8_e4m3b11\n"
          ]
        }
      ],
      "source": [
        "# 在 Google Colab Rsearch 中需要安装的库\n",
        "# !pip install gym[atari]\n",
        "# !pip install autorom[accept-rom-license]\n",
        "\n",
        "import gym, random, pickle, os.path, math, glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import pdb\n",
        "\n",
        "from gym.wrappers import AtariPreprocessing, LazyFrames, FrameStack\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Atari游戏中的Pong\n",
        "\n",
        "Pong是Atari中一个仿真打乒乓球的游戏：玩家和电脑每人拿一个板子，接对方弹来的球，没接住的话，对方得一分，先得到21分的获胜。\n",
        "\n",
        "我们使用 DQN 论文中的设定，在丢失声明时会结束游戏，并且4帧画面会合并为1个输入，加快学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "TaTmabj6NroQ",
        "outputId": "f8ad7d9e-07b3-4ae7-9dd6-5ee3d63c15d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f14fb6eb400>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create and wrap the environment\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "# env.render()\n",
        "test = env.reset()\n",
        "for i in range(100):\n",
        "    test = env.step(env.action_space.sample())[0]\n",
        "\n",
        "plt.imshow(test.__array__()[0,...])\n",
        "\n",
        "# env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Deep-Q Network\n",
        "\n",
        "对于复杂的问题，state维度非常大，我们很难基于tabular method来判断每一个(state, action)的价值。这种情况下，我们利用function approximation方法，构建一个深度神经网络(Deep-Q Network, DQN)，来估计(state, action)的价值。value()中Deep-Q Network模块就是一个神经网络，输入是atari game中的一帧图像，输出是每个action的价值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "X_yXh2wANroR"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_channels=4, num_actions=5):\n",
        "        \"\"\"\n",
        "        Initialize a deep Q-learning network as described in\n",
        "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
        "        Arguments:\n",
        "            in_channels: number of channel of input.\n",
        "                i.e The number of most recent frames stacked together as describe in the paper\n",
        "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
        "        \"\"\"\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.fc5 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.reshape(x.size(0), -1)))\n",
        "        return self.fc5(x)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Memory\n",
        "因为深度神经网络收敛很慢，需要非常多的样本，如果只根据环境交互来训练网络，将非常的没效率。因此DQN引入了一个memory buffer来进行memory replay，就是把之前和环境交互的经验存下来，在训练时重复利用。memory buffer主要实现两个函数：`push`函数将经验存入，`sample`函数将经验取出用于训练。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pFHzSKOqNroS"
      },
      "outputs": [],
      "source": [
        "class Memory_Buffer(object):\n",
        "    def __init__(self, memory_size=100000):\n",
        "        self.buffer = []\n",
        "        self.memory_size = memory_size\n",
        "        self.next_idx = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        data = (state, action, reward, next_state, done)\n",
        "        if len(self.buffer) <= self.memory_size: # buffer not full\n",
        "            self.buffer.append(data)\n",
        "        else: # buffer is full\n",
        "            self.buffer[self.next_idx] = data\n",
        "        self.next_idx = (self.next_idx + 1) % self.memory_size\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            idx = random.randint(0, self.size() - 1)\n",
        "            data = self.buffer[idx]\n",
        "            state, action, reward, next_state, done= data\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(next_state)\n",
        "            dones.append(done)\n",
        "\n",
        "        return np.concatenate(states), actions, rewards, np.concatenate(next_states), dones\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent\n",
        "\n",
        "下面，我们要写最复杂的部分，实现基于DQN的智能体。我们分别实现了下列函数：\n",
        "\n",
        "- `__init__`: 初始化DQN智能体的参数和网络。\n",
        "- `observe`: 将Atari环境每一步返回的observation（numpy矩阵）转为状态（pytorch tensor）。\n",
        "- `value`: 返回状态的Q值。\n",
        "- `act`: 给定状态，根据epsilon greedy算法给出当前动作。\n",
        "- `sample_from_buffer`: 学习相关，从memory buffer抽样经验。\n",
        "- `compute_td_loss`: 学习相关，利用从memory buffer抽样的经验计算TD Loss。\n",
        "- `learn_from_experience`: 学习相关，利用TD Loss进行梯度下降，优化网络。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2VnmExe-NroS"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, in_channels = 1, action_space = [], USE_CUDA = False, memory_size = 10000, epsilon  = 1, lr = 1e-4):\n",
        "        self.epsilon = epsilon\n",
        "        self.action_space = action_space\n",
        "        self.memory_buffer = Memory_Buffer(memory_size)\n",
        "        self.DQN = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target.load_state_dict(self.DQN.state_dict())\n",
        "\n",
        "        self.USE_CUDA = USE_CUDA\n",
        "        if USE_CUDA:\n",
        "            self.DQN = self.DQN.cuda()\n",
        "            self.DQN_target = self.DQN_target.cuda()\n",
        "        self.optimizer = optim.RMSprop(self.DQN.parameters(),lr=lr, eps=0.001, alpha=0.95)\n",
        "\n",
        "    def observe(self, lazyframe):\n",
        "        # from Lazy frame to tensor\n",
        "        state =  torch.from_numpy(lazyframe.__array__()[None]/255).float()\n",
        "        if self.USE_CUDA:\n",
        "            state = state.cuda()\n",
        "        return state\n",
        "\n",
        "    def value(self, state):\n",
        "        q_values = self.DQN(state)\n",
        "        return q_values\n",
        "\n",
        "    def act(self, state, epsilon = None):\n",
        "        \"\"\"\n",
        "        sample actions with epsilon-greedy policy\n",
        "        recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
        "        \"\"\"\n",
        "        if epsilon is None: epsilon = self.epsilon\n",
        "\n",
        "        q_values = self.value(state).cpu().detach().numpy()\n",
        "        if random.random()<epsilon:\n",
        "            aciton = random.randrange(self.action_space.n)\n",
        "        else:\n",
        "            aciton = q_values.argmax(1)[0]\n",
        "        return aciton\n",
        "\n",
        "    def compute_td_loss(self, states, actions, rewards, next_states, is_done, gamma=0.99):\n",
        "        \"\"\" Compute td loss using torch operations only. Use the formula above. \"\"\"\n",
        "        actions = torch.tensor(actions).long()    # shape: [batch_size]\n",
        "        rewards = torch.tensor(rewards, dtype =torch.float)  # shape: [batch_size]\n",
        "        is_done = torch.tensor(is_done).bool()  # shape: [batch_size]\n",
        "\n",
        "        if self.USE_CUDA:\n",
        "            actions = actions.cuda()\n",
        "            rewards = rewards.cuda()\n",
        "            is_done = is_done.cuda()\n",
        "\n",
        "        # get q-values for all actions in current states\n",
        "        predicted_qvalues = self.DQN(states)\n",
        "\n",
        "        # select q-values for chosen actions\n",
        "        predicted_qvalues_for_actions = predicted_qvalues[\n",
        "          range(states.shape[0]), actions\n",
        "        ]\n",
        "\n",
        "        # compute q-values for all actions in next states\n",
        "        predicted_next_qvalues = self.DQN_target(next_states) # YOUR CODE\n",
        "\n",
        "        # compute V*(next_states) using predicted next q-values\n",
        "        next_state_values =  predicted_next_qvalues.max(-1)[0] # YOUR CODE\n",
        "\n",
        "        # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
        "        target_qvalues_for_actions = rewards + gamma *next_state_values # YOUR CODE\n",
        "\n",
        "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
        "        target_qvalues_for_actions = torch.where(\n",
        "            is_done, rewards, target_qvalues_for_actions)\n",
        "\n",
        "        # mean squared error loss to minimize\n",
        "        #loss = torch.mean((predicted_qvalues_for_actions -\n",
        "        #                   target_qvalues_for_actions.detach()) ** 2)\n",
        "        loss = F.smooth_l1_loss(predicted_qvalues_for_actions, target_qvalues_for_actions.detach())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def sample_from_buffer(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "            idx = random.randint(0, self.memory_buffer.size() - 1)\n",
        "            data = self.memory_buffer.buffer[idx]\n",
        "            frame, action, reward, next_frame, done= data\n",
        "            states.append(self.observe(frame))\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(self.observe(next_frame))\n",
        "            dones.append(done)\n",
        "        return torch.cat(states), actions, rewards, torch.cat(next_states), dones\n",
        "\n",
        "    def learn_from_experience(self, batch_size):\n",
        "        if self.memory_buffer.size() > batch_size:\n",
        "            states, actions, rewards, next_states, dones = self.sample_from_buffer(batch_size)\n",
        "            td_loss = self.compute_td_loss(states, actions, rewards, next_states, dones)\n",
        "            self.optimizer.zero_grad()\n",
        "            td_loss.backward()\n",
        "            for param in self.DQN.parameters():\n",
        "                param.grad.data.clamp_(-1, 1)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            return(td_loss.item())\n",
        "        else:\n",
        "            return(0)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Traning\n",
        "\n",
        "接下来是最重要的训练部分，基本上就是定好初始参数，要训练的总帧数，然后让智能体与环境交互并学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsrAIr7TNroT",
        "outputId": "e1577d15-195e-4649-b798-e1d34c63adcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames:     0, reward:   nan, loss: 0.000000, epsilon: 1.000000, episode:    0\n",
            "frames:  1000, reward: -20.000000, loss: 0.000000, epsilon: 0.968855, episode:    1\n",
            "frames:  2000, reward: -20.000000, loss: 0.000000, epsilon: 0.938732, episode:    1\n",
            "frames:  3000, reward: -20.000000, loss: 0.000000, epsilon: 0.909596, episode:    3\n",
            "frames:  4000, reward: -20.250000, loss: 0.000000, epsilon: 0.881415, episode:    4\n",
            "frames:  5000, reward: -19.800000, loss: 0.000000, epsilon: 0.854158, episode:    5\n",
            "frames:  6000, reward: -20.000000, loss: 0.000000, epsilon: 0.827794, episode:    6\n",
            "frames:  7000, reward: -20.142857, loss: 0.000000, epsilon: 0.802295, episode:    7\n",
            "frames:  8000, reward: -20.333333, loss: 0.000000, epsilon: 0.777632, episode:    9\n",
            "frames:  9000, reward: -20.400000, loss: 0.000000, epsilon: 0.753777, episode:   10\n",
            "frames: 10000, reward: -20.500000, loss: 0.015006, epsilon: 0.730705, episode:   11\n",
            "frames: 11000, reward: -20.600000, loss: 0.015339, epsilon: 0.708389, episode:   12\n",
            "frames: 12000, reward: -20.400000, loss: 0.030417, epsilon: 0.686804, episode:   13\n",
            "frames: 13000, reward: -20.400000, loss: 0.015504, epsilon: 0.665927, episode:   14\n",
            "frames: 14000, reward: -20.300000, loss: 0.000243, epsilon: 0.645735, episode:   15\n",
            "frames: 15000, reward: -20.000000, loss: 0.014063, epsilon: 0.626204, episode:   17\n",
            "frames: 16000, reward: -20.000000, loss: 0.015310, epsilon: 0.607314, episode:   18\n",
            "frames: 17000, reward: -19.900000, loss: 0.000627, epsilon: 0.589043, episode:   19\n",
            "frames: 18000, reward: -19.900000, loss: 0.015577, epsilon: 0.571371, episode:   20\n",
            "frames: 19000, reward: -19.700000, loss: 0.000137, epsilon: 0.554278, episode:   21\n",
            "frames: 20000, reward: -19.700000, loss: 0.000225, epsilon: 0.537746, episode:   22\n",
            "frames: 21000, reward: -19.800000, loss: 0.000304, epsilon: 0.521756, episode:   23\n",
            "frames: 22000, reward: -19.600000, loss: 0.000069, epsilon: 0.506290, episode:   24\n",
            "frames: 23000, reward: -19.900000, loss: 0.000526, epsilon: 0.491331, episode:   25\n",
            "frames: 24000, reward: -19.900000, loss: 0.011583, epsilon: 0.476863, episode:   26\n",
            "frames: 25000, reward: -20.000000, loss: 0.030550, epsilon: 0.462868, episode:   27\n",
            "frames: 26000, reward: -20.000000, loss: 0.000159, epsilon: 0.449333, episode:   28\n",
            "frames: 27000, reward: -20.100000, loss: 0.029523, epsilon: 0.436241, episode:   30\n",
            "frames: 28000, reward: -20.300000, loss: 0.000606, epsilon: 0.423579, episode:   31\n",
            "frames: 29000, reward: -20.200000, loss: 0.015362, epsilon: 0.411331, episode:   32\n",
            "frames: 30000, reward: -20.100000, loss: 0.000134, epsilon: 0.399485, episode:   33\n",
            "frames: 31000, reward: -20.300000, loss: 0.030215, epsilon: 0.388028, episode:   34\n",
            "frames: 32000, reward: -20.300000, loss: 0.000039, epsilon: 0.376946, episode:   35\n",
            "frames: 33000, reward: -20.500000, loss: 0.000711, epsilon: 0.366228, episode:   36\n",
            "frames: 34000, reward: -20.300000, loss: 0.044813, epsilon: 0.355860, episode:   37\n",
            "frames: 35000, reward: -20.200000, loss: 0.015289, epsilon: 0.345833, episode:   38\n",
            "frames: 36000, reward: -20.200000, loss: 0.046345, epsilon: 0.336135, episode:   40\n",
            "frames: 37000, reward: -20.100000, loss: 0.000864, epsilon: 0.326754, episode:   41\n",
            "frames: 38000, reward: -20.300000, loss: 0.015155, epsilon: 0.317681, episode:   42\n",
            "frames: 39000, reward: -20.400000, loss: 0.000658, epsilon: 0.308905, episode:   43\n",
            "frames: 40000, reward: -20.400000, loss: 0.000096, epsilon: 0.300417, episode:   44\n",
            "frames: 41000, reward: -20.500000, loss: 0.016093, epsilon: 0.292208, episode:   45\n",
            "frames: 42000, reward: -20.700000, loss: 0.015165, epsilon: 0.284267, episode:   47\n",
            "frames: 43000, reward: -20.800000, loss: 0.000402, epsilon: 0.276587, episode:   48\n",
            "frames: 44000, reward: -20.800000, loss: 0.000187, epsilon: 0.269159, episode:   49\n",
            "frames: 45000, reward: -20.800000, loss: 0.029316, epsilon: 0.261974, episode:   50\n",
            "frames: 46000, reward: -20.900000, loss: 0.014796, epsilon: 0.255024, episode:   51\n",
            "frames: 47000, reward: -20.900000, loss: 0.029547, epsilon: 0.248303, episode:   52\n",
            "frames: 48000, reward: -21.000000, loss: 0.060029, epsilon: 0.241802, episode:   53\n",
            "frames: 49000, reward: -20.800000, loss: 0.030703, epsilon: 0.235514, episode:   55\n",
            "frames: 50000, reward: -20.800000, loss: 0.000256, epsilon: 0.229432, episode:   56\n",
            "frames: 51000, reward: -20.800000, loss: 0.000333, epsilon: 0.223549, episode:   57\n",
            "frames: 52000, reward: -20.800000, loss: 0.001257, epsilon: 0.217860, episode:   58\n",
            "frames: 53000, reward: -20.800000, loss: 0.022521, epsilon: 0.212357, episode:   59\n",
            "frames: 54000, reward: -20.700000, loss: 0.007153, epsilon: 0.207034, episode:   60\n",
            "frames: 55000, reward: -20.500000, loss: 0.002334, epsilon: 0.201886, episode:   61\n",
            "frames: 56000, reward: -20.300000, loss: 0.002344, epsilon: 0.196906, episode:   62\n",
            "frames: 57000, reward: -20.400000, loss: 0.017378, epsilon: 0.192090, episode:   64\n",
            "frames: 58000, reward: -20.300000, loss: 0.007723, epsilon: 0.187432, episode:   65\n",
            "frames: 59000, reward: -20.300000, loss: 0.001621, epsilon: 0.182926, episode:   66\n",
            "frames: 60000, reward: -20.300000, loss: 0.004116, epsilon: 0.178569, episode:   67\n",
            "frames: 61000, reward: -20.300000, loss: 0.004020, epsilon: 0.174354, episode:   68\n",
            "frames: 62000, reward: -20.300000, loss: 0.005219, epsilon: 0.170277, episode:   69\n",
            "frames: 63000, reward: -20.600000, loss: 0.004307, epsilon: 0.166334, episode:   71\n",
            "frames: 64000, reward: -20.800000, loss: 0.001022, epsilon: 0.162520, episode:   72\n",
            "frames: 65000, reward: -20.800000, loss: 0.005565, epsilon: 0.158831, episode:   73\n",
            "frames: 66000, reward: -20.800000, loss: 0.000940, epsilon: 0.155263, episode:   74\n",
            "frames: 67000, reward: -20.900000, loss: 0.002426, epsilon: 0.151812, episode:   75\n",
            "frames: 68000, reward: -20.800000, loss: 0.002548, epsilon: 0.148474, episode:   77\n",
            "frames: 69000, reward: -20.800000, loss: 0.001696, epsilon: 0.145246, episode:   78\n",
            "frames: 70000, reward: -20.800000, loss: 0.012093, epsilon: 0.142123, episode:   79\n",
            "frames: 71000, reward: -20.600000, loss: 0.001570, epsilon: 0.139103, episode:   80\n",
            "frames: 72000, reward: -20.400000, loss: 0.001393, epsilon: 0.136182, episode:   81\n",
            "frames: 73000, reward: -20.400000, loss: 0.000825, epsilon: 0.133357, episode:   82\n",
            "frames: 74000, reward: -20.400000, loss: 0.000892, epsilon: 0.130624, episode:   83\n",
            "frames: 75000, reward: -20.400000, loss: 0.001577, epsilon: 0.127981, episode:   84\n",
            "frames: 76000, reward: -20.300000, loss: 0.002478, epsilon: 0.125424, episode:   85\n",
            "frames: 77000, reward: -20.400000, loss: 0.000952, epsilon: 0.122952, episode:   86\n",
            "frames: 78000, reward: -20.300000, loss: 0.002204, epsilon: 0.120560, episode:   87\n",
            "frames: 79000, reward: -20.300000, loss: 0.007062, epsilon: 0.118247, episode:   89\n",
            "frames: 80000, reward: -20.400000, loss: 0.001367, epsilon: 0.116009, episode:   90\n",
            "frames: 81000, reward: -20.500000, loss: 0.002477, epsilon: 0.113845, episode:   91\n",
            "frames: 82000, reward: -20.500000, loss: 0.000874, epsilon: 0.111752, episode:   92\n",
            "frames: 83000, reward: -20.400000, loss: 0.000912, epsilon: 0.109728, episode:   93\n",
            "frames: 84000, reward: -20.500000, loss: 0.001354, epsilon: 0.107770, episode:   94\n",
            "frames: 85000, reward: -20.600000, loss: 0.002631, epsilon: 0.105876, episode:   95\n",
            "frames: 86000, reward: -20.600000, loss: 0.003812, epsilon: 0.104044, episode:   96\n",
            "frames: 87000, reward: -20.700000, loss: 0.000584, epsilon: 0.102272, episode:   98\n",
            "frames: 88000, reward: -20.700000, loss: 0.002449, epsilon: 0.100558, episode:   98\n",
            "frames: 89000, reward: -20.700000, loss: 0.002212, epsilon: 0.098901, episode:   99\n",
            "frames: 90000, reward: -20.800000, loss: 0.002638, epsilon: 0.097298, episode:  100\n",
            "frames: 91000, reward: -20.900000, loss: 0.001160, epsilon: 0.095747, episode:  101\n",
            "frames: 92000, reward: -20.900000, loss: 0.003304, epsilon: 0.094247, episode:  102\n",
            "frames: 93000, reward: -21.000000, loss: 0.000919, epsilon: 0.092797, episode:  103\n",
            "frames: 94000, reward: -21.000000, loss: 0.000890, epsilon: 0.091394, episode:  104\n",
            "frames: 95000, reward: -21.000000, loss: 0.004785, epsilon: 0.090037, episode:  105\n",
            "frames: 96000, reward: -20.900000, loss: 0.004902, epsilon: 0.088724, episode:  106\n",
            "frames: 97000, reward: -20.900000, loss: 0.001434, epsilon: 0.087455, episode:  107\n",
            "frames: 98000, reward: -20.900000, loss: 0.003306, epsilon: 0.086227, episode:  108\n",
            "frames: 99000, reward: -20.700000, loss: 0.002157, epsilon: 0.085039, episode:  109\n",
            "frames: 100000, reward: -20.600000, loss: 0.001317, epsilon: 0.083890, episode:  110\n",
            "frames: 101000, reward: -20.400000, loss: 0.017545, epsilon: 0.082779, episode:  111\n",
            "frames: 102000, reward: -20.300000, loss: 0.003890, epsilon: 0.081705, episode:  112\n",
            "frames: 103000, reward: -20.200000, loss: 0.001678, epsilon: 0.080665, episode:  113\n",
            "frames: 104000, reward: -20.200000, loss: 0.000882, epsilon: 0.079660, episode:  114\n",
            "frames: 105000, reward: -20.200000, loss: 0.003738, epsilon: 0.078688, episode:  115\n",
            "frames: 106000, reward: -20.300000, loss: 0.000946, epsilon: 0.077747, episode:  116\n",
            "frames: 107000, reward: -20.300000, loss: 0.006670, epsilon: 0.076837, episode:  117\n",
            "frames: 108000, reward: -20.300000, loss: 0.000709, epsilon: 0.075958, episode:  118\n",
            "frames: 109000, reward: -20.500000, loss: 0.002426, epsilon: 0.075107, episode:  119\n",
            "frames: 110000, reward: -20.500000, loss: 0.003445, epsilon: 0.074283, episode:  120\n",
            "frames: 111000, reward: -20.700000, loss: 0.002423, epsilon: 0.073487, episode:  121\n",
            "frames: 112000, reward: -20.800000, loss: 0.001779, epsilon: 0.072717, episode:  122\n",
            "frames: 113000, reward: -20.800000, loss: 0.007298, epsilon: 0.071973, episode:  122\n",
            "frames: 114000, reward: -20.900000, loss: 0.004011, epsilon: 0.071252, episode:  123\n",
            "frames: 115000, reward: -20.800000, loss: 0.003043, epsilon: 0.070556, episode:  124\n"
          ]
        }
      ],
      "source": [
        "# if __name__ == '__main__':\n",
        "\n",
        "# Training DQN in PongNoFrameskip-v4\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "gamma = 0.99\n",
        "epsilon_max = 1\n",
        "epsilon_min = 0.05\n",
        "eps_decay = 30000\n",
        "frames = 2000000\n",
        "USE_CUDA = False\n",
        "learning_rate = 2e-4\n",
        "max_buff = 100000\n",
        "update_tar_interval = 1000\n",
        "batch_size = 32\n",
        "print_interval = 1000\n",
        "log_interval = 1000\n",
        "learning_start = 10000\n",
        "win_reward = 18     # Pong-v4\n",
        "win_break = True\n",
        "\n",
        "action_space = env.action_space\n",
        "action_dim = env.action_space.n\n",
        "state_dim = env.observation_space.shape[1]\n",
        "state_channel = env.observation_space.shape[0]\n",
        "agent = DQNAgent(in_channels = state_channel, action_space= action_space, USE_CUDA = USE_CUDA, lr = learning_rate, memory_size = max_buff)\n",
        "\n",
        "frame = env.reset()\n",
        "\n",
        "episode_reward = 0\n",
        "all_rewards = []\n",
        "losses = []\n",
        "episode_num = 0\n",
        "is_win = False\n",
        "# tensorboard\n",
        "summary_writer = SummaryWriter(log_dir = \"DQN_stackframe\", comment= \"good_makeatari\")\n",
        "\n",
        "# e-greedy decay\n",
        "epsilon_by_frame = lambda frame_idx: epsilon_min + (epsilon_max - epsilon_min) * math.exp(\n",
        "            -1. * frame_idx / eps_decay)\n",
        "# plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
        "\n",
        "for i in range(frames):\n",
        "    epsilon = epsilon_by_frame(i)\n",
        "    state_tensor = agent.observe(frame)\n",
        "    action = agent.act(state_tensor, epsilon)\n",
        "\n",
        "    next_frame, reward, done ,_ = env.step(action)\n",
        "\n",
        "    episode_reward += reward\n",
        "    agent.memory_buffer.push(frame, action, reward, next_frame, done)\n",
        "    frame = next_frame\n",
        "\n",
        "    loss = 0\n",
        "    if agent.memory_buffer.size() >= learning_start:\n",
        "        loss = agent.learn_from_experience(batch_size)\n",
        "        losses.append(loss)\n",
        "\n",
        "    if i % print_interval == 0:\n",
        "        print(\"frames: %5d, reward: %5f, loss: %4f, epsilon: %5f, episode: %4d\" % (i, np.mean(all_rewards[-10:]), loss, epsilon, episode_num))\n",
        "        summary_writer.add_scalar(\"Temporal Difference Loss\", loss, i)\n",
        "        summary_writer.add_scalar(\"Mean Reward\", np.mean(all_rewards[-10:]), i)\n",
        "        summary_writer.add_scalar(\"Epsilon\", epsilon, i)\n",
        "\n",
        "    if i % update_tar_interval == 0:\n",
        "        agent.DQN_target.load_state_dict(agent.DQN.state_dict())\n",
        "\n",
        "    if done:\n",
        "\n",
        "        frame = env.reset()\n",
        "\n",
        "        all_rewards.append(episode_reward)\n",
        "        episode_reward = 0\n",
        "        episode_num += 1\n",
        "        avg_reward = float(np.mean(all_rewards[-100:]))\n",
        "\n",
        "summary_writer.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "下面我们使用matplotlib库画出游戏得分和loss曲线。\n",
        "\n",
        "从左边的图我们可以看到，DQN智能体在玩了200把游戏后开始快速学习，大概在300把游戏之后学习成功（达到20+分）。\n",
        "\n",
        "从右边的图我们可以看到，在表现达到最优之后，Loss还是在不断减小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ekyfJGaNroU",
        "outputId": "bbb8cf5a-a90b-4da1-e35d-6b5c224b911b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_training(frame_idx, rewards, losses):\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    plt.plot(rewards)\n",
        "    plt.subplot(132)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "plot_training(i, all_rewards, losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeaTvisTCI1K"
      },
      "outputs": [],
      "source": [
        "## 总结\n",
        "\n",
        "感想就是，总结强化学习需要的元素相对容易，真正实现的时候很麻烦，尤其是当模型学不会的时候，你会怀疑是模型的问题还是代码有bug，不要犹豫，是代码有bug。\n",
        "\n",
        "训练模型收敛大概需要2百万步，差不多要24小时+，比较慢，但是很欣慰的是Pong在atari game中是最容易实现的游戏，没有bug的话可以在10小时以内收敛，很良心。\n",
        "\n",
        "DQN算法非常经典，值得学习，建议大家都自己实现一遍。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
