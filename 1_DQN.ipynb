{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, random, pickle, os.path, math, glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import pdb\n",
    "\n",
    "from baselines import bench\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind,LazyFrames\n",
    "from IPython.display import clear_output\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bc64491d88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and wrap the environment\n",
    "env = make_atari('PongNoFrameskip-v4') # only use in no frameskip environment\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True )\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "# env.render()\n",
    "test = env.reset()\n",
    "for i in range(100):\n",
    "    test = env.step(env.action_space.sample())[0]\n",
    "\n",
    "plt.imshow(test._force()[...,0])\n",
    "\n",
    "#plt.imshow(env.render(\"rgb_array\"))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels=4, num_actions=5):\n",
    "        \"\"\"\n",
    "        Initialize a deep Q-learning network as described in\n",
    "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "        Arguments:\n",
    "            in_channels: number of channel of input.\n",
    "                i.e The number of most recent frames stacked together as describe in the paper\n",
    "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
    "        return self.fc5(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory_Buffer(object):\n",
    "    def __init__(self, memory_size=1000):\n",
    "        self.buffer = []\n",
    "        self.memory_size = memory_size\n",
    "        self.next_idx = 0\n",
    "        \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        data = (state, action, reward, next_state, done)\n",
    "        if len(self.buffer) <= self.memory_size: # buffer not full\n",
    "            self.buffer.append(data)\n",
    "        else: # buffer is full\n",
    "            self.buffer[self.next_idx] = data\n",
    "        self.next_idx = (self.next_idx + 1) % self.memory_size\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randint(0, self.size() - 1)\n",
    "            data = self.buffer[idx]\n",
    "            state, action, reward, next_state, done= data\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "            \n",
    "            \n",
    "        return np.concatenate(states), actions, rewards, np.concatenate(next_states), dones\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent: \n",
    "    def __init__(self, in_channels = 1, action_space = [], USE_CUDA = False, memory_size = 10000, epsilon  = 1, lr = 1e-4):\n",
    "        self.epsilon = epsilon\n",
    "        self.action_space = action_space\n",
    "        self.memory_buffer = Memory_Buffer(memory_size)\n",
    "        self.DQN = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
    "        self.DQN_target = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
    "        self.DQN_target.load_state_dict(self.DQN.state_dict())\n",
    "\n",
    "\n",
    "        self.USE_CUDA = USE_CUDA\n",
    "        if USE_CUDA:\n",
    "            self.DQN = self.DQN.cuda()\n",
    "            self.DQN_target = self.DQN_target.cuda()\n",
    "        self.optimizer = optim.RMSprop(self.DQN.parameters(),lr=lr, eps=0.001, alpha=0.95)\n",
    "\n",
    "    def observe(self, lazyframe):\n",
    "        # from Lazy frame to tensor\n",
    "        state =  torch.from_numpy(lazyframe._force().transpose(2,0,1)[None]/255).float()\n",
    "        if self.USE_CUDA:\n",
    "            state = state.cuda()\n",
    "        return state\n",
    "\n",
    "    def value(self, state):\n",
    "        q_values = self.DQN(state)\n",
    "        return q_values\n",
    "    \n",
    "    def act(self, state, epsilon = None):\n",
    "        \"\"\"\n",
    "        sample actions with epsilon-greedy policy\n",
    "        recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
    "        \"\"\"\n",
    "        if epsilon is None: epsilon = self.epsilon\n",
    "\n",
    "        q_values = self.value(state).cpu().detach().numpy()\n",
    "        if random.random()<epsilon:\n",
    "            aciton = random.randrange(self.action_space.n)\n",
    "        else:\n",
    "            aciton = q_values.argmax(1)[0]\n",
    "        return aciton\n",
    "    \n",
    "    def compute_td_loss(self, states, actions, rewards, next_states, is_done, gamma=0.99):\n",
    "        \"\"\" Compute td loss using torch operations only. Use the formula above. \"\"\"\n",
    "        actions = torch.tensor(actions).long()    # shape: [batch_size]\n",
    "        rewards = torch.tensor(rewards, dtype =torch.float)  # shape: [batch_size]\n",
    "        is_done = torch.tensor(is_done).bool()  # shape: [batch_size]\n",
    "        \n",
    "        if self.USE_CUDA:\n",
    "            actions = actions.cuda()\n",
    "            rewards = rewards.cuda()\n",
    "            is_done = is_done.cuda()\n",
    "\n",
    "        # get q-values for all actions in current states\n",
    "        predicted_qvalues = self.DQN(states)\n",
    "\n",
    "        # select q-values for chosen actions\n",
    "        predicted_qvalues_for_actions = predicted_qvalues[\n",
    "          range(states.shape[0]), actions\n",
    "        ]\n",
    "\n",
    "        # compute q-values for all actions in next states\n",
    "        predicted_next_qvalues = self.DQN_target(next_states) # YOUR CODE\n",
    "\n",
    "        # compute V*(next_states) using predicted next q-values\n",
    "        next_state_values =  predicted_next_qvalues.max(-1)[0] # YOUR CODE\n",
    "\n",
    "        # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "        target_qvalues_for_actions = rewards + gamma *next_state_values # YOUR CODE\n",
    "\n",
    "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "        target_qvalues_for_actions = torch.where(\n",
    "            is_done, rewards, target_qvalues_for_actions)\n",
    "\n",
    "        # mean squared error loss to minimize\n",
    "        #loss = torch.mean((predicted_qvalues_for_actions -\n",
    "        #                   target_qvalues_for_actions.detach()) ** 2)\n",
    "        loss = F.smooth_l1_loss(predicted_qvalues_for_actions, target_qvalues_for_actions.detach())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def sample_from_buffer(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randint(0, self.memory_buffer.size() - 1)\n",
    "            data = self.memory_buffer.buffer[idx]\n",
    "            frame, action, reward, next_frame, done= data\n",
    "            states.append(self.observe(frame))\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(self.observe(next_frame))\n",
    "            dones.append(done)\n",
    "        return torch.cat(states), actions, rewards, torch.cat(next_states), dones\n",
    "\n",
    "    def learn_from_experience(self, batch_size):\n",
    "        if self.memory_buffer.size() > batch_size:\n",
    "            states, actions, rewards, next_states, dones = self.sample_from_buffer(batch_size)\n",
    "            td_loss = self.compute_td_loss(states, actions, rewards, next_states, dones)\n",
    "            self.optimizer.zero_grad()\n",
    "            td_loss.backward()\n",
    "            for param in self.DQN.parameters():\n",
    "                param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            return(td_loss.item())\n",
    "        else:\n",
    "            return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\softwares\\ANACONDA\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "F:\\softwares\\ANACONDA\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:root:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames:     0, reward:   nan, loss: 0.000000, epsilon: 1.000000, episode:    0\n",
      "frames:  1000, reward: -21.000000, loss: 0.000000, epsilon: 0.967544, episode:    1\n",
      "frames:  2000, reward: -21.000000, loss: 0.000000, epsilon: 0.936152, episode:    2\n",
      "frames:  3000, reward: -20.666667, loss: 0.000000, epsilon: 0.905789, episode:    3\n",
      "frames:  4000, reward: -20.500000, loss: 0.000000, epsilon: 0.876422, episode:    4\n",
      "frames:  5000, reward: -20.600000, loss: 0.000000, epsilon: 0.848017, episode:    5\n",
      "frames:  6000, reward: -20.666667, loss: 0.000000, epsilon: 0.820543, episode:    6\n",
      "frames:  7000, reward: -20.714286, loss: 0.000000, epsilon: 0.793971, episode:    7\n",
      "frames:  8000, reward: -20.750000, loss: 0.000000, epsilon: 0.768269, episode:    8\n",
      "frames:  9000, reward: -20.666667, loss: 0.000000, epsilon: 0.743410, episode:    9\n",
      "frames: 10000, reward: -20.700000, loss: 0.000681, epsilon: 0.719366, episode:   11\n",
      "frames: 11000, reward: -20.700000, loss: 0.000297, epsilon: 0.696110, episode:   12\n",
      "frames: 12000, reward: -20.700000, loss: 0.000405, epsilon: 0.673617, episode:   13\n",
      "frames: 13000, reward: -20.700000, loss: 0.000196, epsilon: 0.651861, episode:   14\n",
      "frames: 14000, reward: -20.600000, loss: 0.000325, epsilon: 0.630818, episode:   15\n",
      "frames: 15000, reward: -20.500000, loss: 0.000416, epsilon: 0.610465, episode:   16\n",
      "frames: 16000, reward: -20.400000, loss: 0.000390, epsilon: 0.590780, episode:   17\n",
      "frames: 17000, reward: -20.200000, loss: 0.014984, epsilon: 0.571740, episode:   18\n",
      "frames: 18000, reward: -20.300000, loss: 0.030162, epsilon: 0.553324, episode:   19\n",
      "frames: 19000, reward: -20.300000, loss: 0.000113, epsilon: 0.535511, episode:   20\n",
      "frames: 20000, reward: -20.300000, loss: 0.029979, epsilon: 0.518283, episode:   21\n",
      "frames: 21000, reward: -20.400000, loss: 0.015212, epsilon: 0.501619, episode:   23\n",
      "frames: 22000, reward: -20.500000, loss: 0.014934, epsilon: 0.485502, episode:   24\n",
      "frames: 23000, reward: -20.400000, loss: 0.015320, epsilon: 0.469913, episode:   25\n",
      "frames: 24000, reward: -20.400000, loss: 0.015695, epsilon: 0.454836, episode:   26\n",
      "frames: 25000, reward: -20.400000, loss: 0.000225, epsilon: 0.440252, episode:   27\n",
      "frames: 26000, reward: -20.600000, loss: 0.000049, epsilon: 0.426147, episode:   28\n",
      "frames: 27000, reward: -20.600000, loss: 0.000935, epsilon: 0.412504, episode:   29\n",
      "frames: 28000, reward: -20.500000, loss: 0.001049, epsilon: 0.399308, episode:   30\n",
      "frames: 29000, reward: -20.500000, loss: 0.015459, epsilon: 0.386545, episode:   31\n",
      "frames: 30000, reward: -20.500000, loss: 0.030076, epsilon: 0.374201, episode:   32\n",
      "frames: 31000, reward: -20.400000, loss: 0.014286, epsilon: 0.362261, episode:   33\n",
      "frames: 32000, reward: -20.300000, loss: 0.000193, epsilon: 0.350712, episode:   34\n",
      "frames: 33000, reward: -20.500000, loss: 0.015142, epsilon: 0.339542, episode:   36\n",
      "frames: 34000, reward: -20.600000, loss: 0.015406, epsilon: 0.328739, episode:   37\n",
      "frames: 35000, reward: -20.500000, loss: 0.000156, epsilon: 0.318289, episode:   38\n",
      "frames: 36000, reward: -20.400000, loss: 0.000129, epsilon: 0.308182, episode:   39\n",
      "frames: 37000, reward: -20.400000, loss: 0.030093, epsilon: 0.298407, episode:   40\n",
      "frames: 38000, reward: -20.200000, loss: 0.000316, epsilon: 0.288952, episode:   41\n",
      "frames: 39000, reward: -20.300000, loss: 0.000433, epsilon: 0.279806, episode:   43\n",
      "frames: 40000, reward: -20.400000, loss: 0.000195, epsilon: 0.270961, episode:   44\n",
      "frames: 41000, reward: -20.500000, loss: 0.015528, epsilon: 0.262406, episode:   45\n",
      "frames: 42000, reward: -20.500000, loss: 0.015188, epsilon: 0.254131, episode:   46\n",
      "frames: 43000, reward: -20.600000, loss: 0.000754, epsilon: 0.246127, episode:   48\n",
      "frames: 44000, reward: -20.700000, loss: 0.000231, epsilon: 0.238386, episode:   49\n",
      "frames: 45000, reward: -20.800000, loss: 0.015452, epsilon: 0.230899, episode:   50\n",
      "frames: 46000, reward: -20.900000, loss: 0.014538, epsilon: 0.223657, episode:   51\n",
      "frames: 47000, reward: -20.700000, loss: 0.029473, epsilon: 0.216652, episode:   52\n",
      "frames: 48000, reward: -20.600000, loss: 0.024520, epsilon: 0.209878, episode:   53\n",
      "frames: 49000, reward: -20.600000, loss: 0.002647, epsilon: 0.203325, episode:   54\n",
      "frames: 50000, reward: -20.600000, loss: 0.026042, epsilon: 0.196987, episode:   55\n",
      "frames: 51000, reward: -20.400000, loss: 0.015549, epsilon: 0.190857, episode:   57\n",
      "frames: 52000, reward: -20.400000, loss: 0.023956, epsilon: 0.184928, episode:   58\n",
      "frames: 53000, reward: -20.400000, loss: 0.002211, epsilon: 0.179193, episode:   59\n",
      "frames: 54000, reward: -20.400000, loss: 0.003971, epsilon: 0.173646, episode:   60\n",
      "frames: 55000, reward: -20.700000, loss: 0.003664, epsilon: 0.168281, episode:   62\n",
      "frames: 56000, reward: -20.800000, loss: 0.003606, epsilon: 0.163092, episode:   63\n",
      "frames: 57000, reward: -20.700000, loss: 0.003617, epsilon: 0.158073, episode:   64\n",
      "frames: 58000, reward: -20.700000, loss: 0.003484, epsilon: 0.153219, episode:   65\n",
      "frames: 59000, reward: -20.900000, loss: 0.002725, epsilon: 0.148523, episode:   66\n",
      "frames: 60000, reward: -20.900000, loss: 0.002768, epsilon: 0.143982, episode:   67\n",
      "frames: 61000, reward: -20.900000, loss: 0.003302, epsilon: 0.139589, episode:   68\n",
      "frames: 62000, reward: -20.800000, loss: 0.002421, epsilon: 0.135341, episode:   69\n",
      "frames: 63000, reward: -20.700000, loss: 0.000843, epsilon: 0.131232, episode:   70\n",
      "frames: 64000, reward: -20.600000, loss: 0.003403, epsilon: 0.127257, episode:   72\n",
      "frames: 65000, reward: -20.600000, loss: 0.003831, epsilon: 0.123413, episode:   73\n",
      "frames: 66000, reward: -20.500000, loss: 0.001257, epsilon: 0.119695, episode:   74\n",
      "frames: 67000, reward: -20.500000, loss: 0.001919, epsilon: 0.116099, episode:   75\n",
      "frames: 68000, reward: -20.400000, loss: 0.000679, epsilon: 0.112621, episode:   76\n",
      "frames: 69000, reward: -20.400000, loss: 0.002319, epsilon: 0.109256, episode:   77\n",
      "frames: 70000, reward: -20.400000, loss: 0.010062, epsilon: 0.106002, episode:   79\n",
      "frames: 71000, reward: -20.500000, loss: 0.000513, epsilon: 0.102855, episode:   80\n",
      "frames: 72000, reward: -20.600000, loss: 0.001251, epsilon: 0.099811, episode:   81\n",
      "frames: 73000, reward: -20.600000, loss: 0.000267, epsilon: 0.096866, episode:   82\n",
      "frames: 74000, reward: -20.700000, loss: 0.000348, epsilon: 0.094019, episode:   84\n",
      "frames: 75000, reward: -20.600000, loss: 0.000972, epsilon: 0.091264, episode:   85\n",
      "frames: 76000, reward: -20.500000, loss: 0.001871, epsilon: 0.088600, episode:   86\n",
      "frames: 77000, reward: -20.400000, loss: 0.000756, epsilon: 0.086023, episode:   87\n",
      "frames: 78000, reward: -20.300000, loss: 0.000554, epsilon: 0.083531, episode:   88\n",
      "frames: 79000, reward: -20.200000, loss: 0.001813, epsilon: 0.081120, episode:   89\n",
      "frames: 80000, reward: -20.100000, loss: 0.001214, epsilon: 0.078789, episode:   90\n",
      "frames: 81000, reward: -19.900000, loss: 0.000636, epsilon: 0.076533, episode:   91\n",
      "frames: 82000, reward: -19.900000, loss: 0.001829, epsilon: 0.074352, episode:   92\n",
      "frames: 83000, reward: -19.900000, loss: 0.001644, epsilon: 0.072243, episode:   93\n",
      "frames: 84000, reward: -19.800000, loss: 0.002911, epsilon: 0.070202, episode:   94\n",
      "frames: 85000, reward: -19.900000, loss: 0.002190, epsilon: 0.068228, episode:   95\n",
      "frames: 86000, reward: -20.100000, loss: 0.001464, epsilon: 0.066319, episode:   96\n",
      "frames: 87000, reward: -20.200000, loss: 0.002358, epsilon: 0.064473, episode:   98\n",
      "frames: 88000, reward: -20.400000, loss: 0.003429, epsilon: 0.062687, episode:   99\n",
      "frames: 89000, reward: -20.500000, loss: 0.001794, epsilon: 0.060960, episode:  100\n",
      "frames: 90000, reward: -20.500000, loss: 0.003789, epsilon: 0.059289, episode:  101\n",
      "frames: 91000, reward: -20.500000, loss: 0.003443, epsilon: 0.057673, episode:  102\n",
      "frames: 92000, reward: -20.500000, loss: 0.002265, epsilon: 0.056110, episode:  103\n",
      "frames: 93000, reward: -20.500000, loss: 0.001802, epsilon: 0.054599, episode:  104\n",
      "frames: 94000, reward: -20.500000, loss: 0.003028, epsilon: 0.053137, episode:  105\n",
      "frames: 95000, reward: -20.400000, loss: 0.000686, epsilon: 0.051722, episode:  106\n",
      "frames: 96000, reward: -20.500000, loss: 0.004434, epsilon: 0.050355, episode:  107\n",
      "frames: 97000, reward: -20.500000, loss: 0.001619, epsilon: 0.049032, episode:  108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 98000, reward: -20.400000, loss: 0.002644, epsilon: 0.047752, episode:  109\n",
      "frames: 99000, reward: -20.600000, loss: 0.001584, epsilon: 0.046514, episode:  111\n",
      "frames: 100000, reward: -20.400000, loss: 0.001171, epsilon: 0.045317, episode:  112\n",
      "frames: 101000, reward: -20.400000, loss: 0.001929, epsilon: 0.044159, episode:  113\n",
      "frames: 102000, reward: -20.500000, loss: 0.004967, epsilon: 0.043040, episode:  114\n",
      "frames: 103000, reward: -20.400000, loss: 0.001417, epsilon: 0.041956, episode:  115\n",
      "frames: 104000, reward: -20.500000, loss: 0.007077, epsilon: 0.040909, episode:  116\n",
      "frames: 105000, reward: -20.500000, loss: 0.001342, epsilon: 0.039895, episode:  117\n",
      "frames: 106000, reward: -20.500000, loss: 0.002944, epsilon: 0.038915, episode:  118\n",
      "frames: 107000, reward: -20.600000, loss: 0.022422, epsilon: 0.037967, episode:  119\n",
      "frames: 108000, reward: -20.600000, loss: 0.002681, epsilon: 0.037050, episode:  119\n",
      "frames: 109000, reward: -20.400000, loss: 0.002142, epsilon: 0.036164, episode:  120\n",
      "frames: 110000, reward: -20.300000, loss: 0.001532, epsilon: 0.035306, episode:  121\n",
      "frames: 111000, reward: -20.300000, loss: 0.002810, epsilon: 0.034476, episode:  122\n",
      "frames: 112000, reward: -20.300000, loss: 0.005303, epsilon: 0.033674, episode:  122\n",
      "frames: 113000, reward: -20.400000, loss: 0.018242, epsilon: 0.032898, episode:  123\n",
      "frames: 114000, reward: -20.100000, loss: 0.000936, epsilon: 0.032147, episode:  124\n",
      "frames: 115000, reward: -20.100000, loss: 0.001674, epsilon: 0.031421, episode:  124\n",
      "frames: 116000, reward: -20.100000, loss: 0.005797, epsilon: 0.030719, episode:  125\n",
      "frames: 117000, reward: -20.000000, loss: 0.002723, epsilon: 0.030039, episode:  126\n",
      "frames: 118000, reward: -19.800000, loss: 0.001635, epsilon: 0.029383, episode:  127\n",
      "frames: 119000, reward: -19.700000, loss: 0.001248, epsilon: 0.028747, episode:  128\n",
      "frames: 120000, reward: -19.600000, loss: 0.002003, epsilon: 0.028132, episode:  129\n",
      "frames: 121000, reward: -19.600000, loss: 0.002055, epsilon: 0.027538, episode:  129\n",
      "frames: 122000, reward: -19.600000, loss: 0.001345, epsilon: 0.026963, episode:  130\n",
      "frames: 123000, reward: -19.600000, loss: 0.001695, epsilon: 0.026407, episode:  130\n",
      "frames: 124000, reward: -19.500000, loss: 0.002027, epsilon: 0.025869, episode:  131\n",
      "frames: 125000, reward: -19.600000, loss: 0.001576, epsilon: 0.025349, episode:  132\n",
      "frames: 126000, reward: -19.600000, loss: 0.002093, epsilon: 0.024846, episode:  132\n",
      "frames: 127000, reward: -19.600000, loss: 0.002089, epsilon: 0.024359, episode:  132\n",
      "frames: 128000, reward: -19.100000, loss: 0.010271, epsilon: 0.023888, episode:  133\n",
      "frames: 129000, reward: -19.200000, loss: 0.004891, epsilon: 0.023433, episode:  134\n",
      "frames: 130000, reward: -19.200000, loss: 0.004831, epsilon: 0.022992, episode:  134\n",
      "frames: 131000, reward: -19.100000, loss: 0.004002, epsilon: 0.022567, episode:  135\n",
      "frames: 132000, reward: -19.200000, loss: 0.001039, epsilon: 0.022155, episode:  136\n",
      "frames: 133000, reward: -19.200000, loss: 0.003955, epsilon: 0.021756, episode:  136\n",
      "frames: 134000, reward: -19.100000, loss: 0.001810, epsilon: 0.021371, episode:  137\n",
      "frames: 135000, reward: -19.100000, loss: 0.000789, epsilon: 0.020998, episode:  138\n",
      "frames: 136000, reward: -19.100000, loss: 0.002639, epsilon: 0.020637, episode:  138\n",
      "frames: 137000, reward: -19.100000, loss: 0.002571, epsilon: 0.020289, episode:  139\n",
      "frames: 138000, reward: -19.100000, loss: 0.005467, epsilon: 0.019951, episode:  139\n",
      "frames: 139000, reward: -18.900000, loss: 0.000964, epsilon: 0.019625, episode:  140\n",
      "frames: 140000, reward: -18.900000, loss: 0.003930, epsilon: 0.019310, episode:  140\n",
      "frames: 141000, reward: -19.000000, loss: 0.002199, epsilon: 0.019004, episode:  141\n",
      "frames: 142000, reward: -18.900000, loss: 0.001582, epsilon: 0.018709, episode:  142\n",
      "frames: 143000, reward: -18.900000, loss: 0.008786, epsilon: 0.018424, episode:  142\n",
      "frames: 144000, reward: -18.900000, loss: 0.006551, epsilon: 0.018147, episode:  142\n",
      "frames: 145000, reward: -18.900000, loss: 0.002679, epsilon: 0.017880, episode:  143\n",
      "frames: 146000, reward: -18.900000, loss: 0.005688, epsilon: 0.017622, episode:  143\n",
      "frames: 147000, reward: -18.700000, loss: 0.003561, epsilon: 0.017372, episode:  144\n",
      "frames: 148000, reward: -18.700000, loss: 0.001506, epsilon: 0.017130, episode:  144\n",
      "frames: 149000, reward: -18.600000, loss: 0.001750, epsilon: 0.016897, episode:  145\n",
      "frames: 150000, reward: -18.600000, loss: 0.005229, epsilon: 0.016671, episode:  145\n",
      "frames: 151000, reward: -18.400000, loss: 0.005065, epsilon: 0.016452, episode:  146\n",
      "frames: 152000, reward: -18.400000, loss: 0.001902, epsilon: 0.016240, episode:  146\n",
      "frames: 153000, reward: -18.200000, loss: 0.001791, epsilon: 0.016036, episode:  147\n",
      "frames: 154000, reward: -18.200000, loss: 0.001312, epsilon: 0.015838, episode:  147\n",
      "frames: 155000, reward: -18.200000, loss: 0.005340, epsilon: 0.015647, episode:  147\n",
      "frames: 156000, reward: -17.600000, loss: 0.002179, epsilon: 0.015461, episode:  148\n",
      "frames: 157000, reward: -17.600000, loss: 0.001575, epsilon: 0.015282, episode:  148\n",
      "frames: 158000, reward: -17.600000, loss: 0.004320, epsilon: 0.015109, episode:  148\n",
      "frames: 159000, reward: -16.800000, loss: 0.002026, epsilon: 0.014942, episode:  149\n",
      "frames: 160000, reward: -16.800000, loss: 0.001287, epsilon: 0.014780, episode:  149\n",
      "frames: 161000, reward: -16.800000, loss: 0.001324, epsilon: 0.014623, episode:  149\n",
      "frames: 162000, reward: -16.400000, loss: 0.004713, epsilon: 0.014471, episode:  150\n",
      "frames: 163000, reward: -16.400000, loss: 0.001936, epsilon: 0.014325, episode:  150\n",
      "frames: 164000, reward: -15.900000, loss: 0.002550, epsilon: 0.014183, episode:  151\n",
      "frames: 165000, reward: -15.900000, loss: 0.001664, epsilon: 0.014046, episode:  151\n",
      "frames: 166000, reward: -15.900000, loss: 0.006812, epsilon: 0.013913, episode:  151\n",
      "frames: 167000, reward: -15.900000, loss: 0.001943, epsilon: 0.013785, episode:  152\n",
      "frames: 168000, reward: -15.900000, loss: 0.001645, epsilon: 0.013661, episode:  152\n",
      "frames: 169000, reward: -16.000000, loss: 0.002415, epsilon: 0.013541, episode:  153\n",
      "frames: 170000, reward: -16.000000, loss: 0.002732, epsilon: 0.013425, episode:  153\n",
      "frames: 171000, reward: -16.000000, loss: 0.001838, epsilon: 0.013313, episode:  153\n",
      "frames: 172000, reward: -16.000000, loss: 0.002776, epsilon: 0.013204, episode:  153\n",
      "frames: 173000, reward: -15.500000, loss: 0.000697, epsilon: 0.013099, episode:  154\n",
      "frames: 174000, reward: -15.500000, loss: 0.002788, epsilon: 0.012997, episode:  154\n",
      "frames: 175000, reward: -15.700000, loss: 0.001066, epsilon: 0.012899, episode:  155\n",
      "frames: 176000, reward: -15.700000, loss: 0.002326, epsilon: 0.012804, episode:  155\n",
      "frames: 177000, reward: -15.700000, loss: 0.001625, epsilon: 0.012712, episode:  155\n",
      "frames: 178000, reward: -15.300000, loss: 0.004043, epsilon: 0.012623, episode:  156\n",
      "frames: 179000, reward: -15.300000, loss: 0.002495, epsilon: 0.012537, episode:  156\n",
      "frames: 180000, reward: -15.300000, loss: 0.002691, epsilon: 0.012454, episode:  156\n",
      "frames: 181000, reward: -15.300000, loss: 0.001590, epsilon: 0.012374, episode:  157\n",
      "frames: 182000, reward: -15.300000, loss: 0.001574, epsilon: 0.012296, episode:  157\n",
      "frames: 183000, reward: -14.600000, loss: 0.001127, epsilon: 0.012220, episode:  158\n",
      "frames: 184000, reward: -14.600000, loss: 0.001787, epsilon: 0.012148, episode:  158\n",
      "frames: 185000, reward: -14.600000, loss: 0.003533, epsilon: 0.012077, episode:  158\n",
      "frames: 186000, reward: -15.100000, loss: 0.001429, epsilon: 0.012009, episode:  159\n",
      "frames: 187000, reward: -15.100000, loss: 0.012204, epsilon: 0.011943, episode:  159\n",
      "frames: 188000, reward: -15.600000, loss: 0.001685, epsilon: 0.011880, episode:  160\n",
      "frames: 189000, reward: -15.600000, loss: 0.001090, epsilon: 0.011818, episode:  160\n",
      "frames: 190000, reward: -15.700000, loss: 0.001833, epsilon: 0.011758, episode:  161\n",
      "frames: 191000, reward: -15.700000, loss: 0.002103, epsilon: 0.011701, episode:  161\n",
      "frames: 192000, reward: -15.400000, loss: 0.001675, epsilon: 0.011645, episode:  162\n",
      "frames: 193000, reward: -15.400000, loss: 0.001798, epsilon: 0.011591, episode:  162\n",
      "frames: 194000, reward: -15.400000, loss: 0.000950, epsilon: 0.011539, episode:  162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 195000, reward: -15.200000, loss: 0.002191, epsilon: 0.011488, episode:  163\n",
      "frames: 196000, reward: -16.000000, loss: 0.002308, epsilon: 0.011440, episode:  164\n",
      "frames: 197000, reward: -16.000000, loss: 0.012042, epsilon: 0.011392, episode:  164\n",
      "frames: 198000, reward: -16.000000, loss: 0.001483, epsilon: 0.011347, episode:  164\n",
      "frames: 199000, reward: -15.100000, loss: 0.002209, epsilon: 0.011303, episode:  165\n",
      "frames: 200000, reward: -15.100000, loss: 0.001894, epsilon: 0.011260, episode:  165\n",
      "frames: 201000, reward: -15.100000, loss: 0.004223, epsilon: 0.011219, episode:  166\n",
      "frames: 202000, reward: -15.100000, loss: 0.001320, epsilon: 0.011179, episode:  166\n",
      "frames: 203000, reward: -15.100000, loss: 0.001523, epsilon: 0.011140, episode:  166\n",
      "frames: 204000, reward: -14.900000, loss: 0.001928, epsilon: 0.011103, episode:  167\n",
      "frames: 205000, reward: -14.900000, loss: 0.001030, epsilon: 0.011066, episode:  167\n",
      "frames: 206000, reward: -14.900000, loss: 0.000991, epsilon: 0.011032, episode:  167\n",
      "frames: 207000, reward: -15.400000, loss: 0.000884, epsilon: 0.010998, episode:  168\n",
      "frames: 208000, reward: -15.400000, loss: 0.001632, epsilon: 0.010965, episode:  168\n",
      "frames: 209000, reward: -15.400000, loss: 0.033099, epsilon: 0.010933, episode:  168\n",
      "frames: 210000, reward: -15.400000, loss: 0.002736, epsilon: 0.010903, episode:  169\n",
      "frames: 211000, reward: -15.400000, loss: 0.002197, epsilon: 0.010873, episode:  169\n",
      "frames: 212000, reward: -15.400000, loss: 0.001300, epsilon: 0.010845, episode:  169\n",
      "frames: 213000, reward: -14.700000, loss: 0.001371, epsilon: 0.010817, episode:  170\n",
      "frames: 214000, reward: -14.700000, loss: 0.002366, epsilon: 0.010790, episode:  170\n",
      "frames: 215000, reward: -14.700000, loss: 0.000702, epsilon: 0.010764, episode:  170\n",
      "frames: 216000, reward: -13.800000, loss: 0.001136, epsilon: 0.010739, episode:  171\n",
      "frames: 217000, reward: -13.800000, loss: 0.003725, epsilon: 0.010715, episode:  171\n",
      "frames: 218000, reward: -13.800000, loss: 0.001042, epsilon: 0.010691, episode:  171\n",
      "frames: 219000, reward: -13.800000, loss: 0.001649, epsilon: 0.010669, episode:  171\n",
      "frames: 220000, reward: -13.600000, loss: 0.001656, epsilon: 0.010647, episode:  172\n",
      "frames: 221000, reward: -13.600000, loss: 0.001197, epsilon: 0.010626, episode:  172\n",
      "frames: 222000, reward: -13.600000, loss: 0.005792, epsilon: 0.010605, episode:  172\n",
      "frames: 223000, reward: -13.300000, loss: 0.003574, epsilon: 0.010585, episode:  173\n",
      "frames: 224000, reward: -13.300000, loss: 0.003120, epsilon: 0.010566, episode:  173\n",
      "frames: 225000, reward: -12.900000, loss: 0.002856, epsilon: 0.010548, episode:  174\n",
      "frames: 226000, reward: -12.900000, loss: 0.001095, epsilon: 0.010530, episode:  174\n",
      "frames: 227000, reward: -12.900000, loss: 0.001637, epsilon: 0.010512, episode:  174\n",
      "frames: 228000, reward: -12.900000, loss: 0.001535, epsilon: 0.010495, episode:  174\n",
      "frames: 229000, reward: -12.900000, loss: 0.001678, epsilon: 0.010479, episode:  175\n",
      "frames: 230000, reward: -12.900000, loss: 0.001957, epsilon: 0.010463, episode:  175\n",
      "frames: 231000, reward: -12.900000, loss: 0.001281, epsilon: 0.010448, episode:  175\n",
      "frames: 232000, reward: -13.000000, loss: 0.001259, epsilon: 0.010434, episode:  176\n",
      "frames: 233000, reward: -13.000000, loss: 0.003476, epsilon: 0.010419, episode:  176\n",
      "frames: 234000, reward: -13.000000, loss: 0.002211, epsilon: 0.010406, episode:  176\n",
      "frames: 235000, reward: -13.200000, loss: 0.000968, epsilon: 0.010392, episode:  177\n",
      "frames: 236000, reward: -13.200000, loss: 0.001170, epsilon: 0.010379, episode:  177\n",
      "frames: 237000, reward: -13.200000, loss: 0.001344, epsilon: 0.010367, episode:  177\n",
      "frames: 238000, reward: -13.200000, loss: 0.000962, epsilon: 0.010355, episode:  177\n",
      "frames: 239000, reward: -13.100000, loss: 0.001725, epsilon: 0.010343, episode:  178\n",
      "frames: 240000, reward: -13.100000, loss: 0.001013, epsilon: 0.010332, episode:  178\n",
      "frames: 241000, reward: -13.100000, loss: 0.001776, epsilon: 0.010321, episode:  178\n",
      "frames: 242000, reward: -13.000000, loss: 0.001729, epsilon: 0.010311, episode:  179\n",
      "frames: 243000, reward: -13.000000, loss: 0.004616, epsilon: 0.010301, episode:  179\n",
      "frames: 244000, reward: -13.000000, loss: 0.000933, epsilon: 0.010291, episode:  179\n",
      "frames: 245000, reward: -13.000000, loss: 0.001274, epsilon: 0.010281, episode:  180\n",
      "frames: 246000, reward: -13.000000, loss: 0.001116, epsilon: 0.010272, episode:  180\n",
      "frames: 247000, reward: -13.000000, loss: 0.001297, epsilon: 0.010263, episode:  180\n",
      "frames: 248000, reward: -13.800000, loss: 0.000915, epsilon: 0.010254, episode:  181\n",
      "frames: 249000, reward: -13.800000, loss: 0.001879, epsilon: 0.010246, episode:  181\n",
      "frames: 250000, reward: -13.800000, loss: 0.002299, epsilon: 0.010238, episode:  181\n",
      "frames: 251000, reward: -14.100000, loss: 0.001092, epsilon: 0.010230, episode:  182\n",
      "frames: 252000, reward: -14.100000, loss: 0.001244, epsilon: 0.010223, episode:  182\n",
      "frames: 253000, reward: -14.100000, loss: 0.002315, epsilon: 0.010215, episode:  182\n",
      "frames: 254000, reward: -14.100000, loss: 0.001373, epsilon: 0.010208, episode:  182\n",
      "frames: 255000, reward: -14.100000, loss: 0.001086, epsilon: 0.010201, episode:  183\n",
      "frames: 256000, reward: -14.100000, loss: 0.000806, epsilon: 0.010195, episode:  183\n",
      "frames: 257000, reward: -14.100000, loss: 0.000629, epsilon: 0.010188, episode:  183\n",
      "frames: 258000, reward: -14.100000, loss: 0.001877, epsilon: 0.010182, episode:  183\n",
      "frames: 259000, reward: -14.100000, loss: 0.000290, epsilon: 0.010176, episode:  184\n",
      "frames: 260000, reward: -14.100000, loss: 0.001857, epsilon: 0.010171, episode:  184\n",
      "frames: 261000, reward: -14.100000, loss: 0.001135, epsilon: 0.010165, episode:  184\n",
      "frames: 262000, reward: -14.100000, loss: 0.000817, epsilon: 0.010160, episode:  184\n",
      "frames: 263000, reward: -14.000000, loss: 0.000896, epsilon: 0.010154, episode:  185\n",
      "frames: 264000, reward: -14.000000, loss: 0.000412, epsilon: 0.010149, episode:  185\n",
      "frames: 265000, reward: -13.900000, loss: 0.001041, epsilon: 0.010144, episode:  186\n",
      "frames: 266000, reward: -13.900000, loss: 0.000491, epsilon: 0.010140, episode:  186\n",
      "frames: 267000, reward: -13.900000, loss: 0.001782, epsilon: 0.010135, episode:  186\n",
      "frames: 268000, reward: -14.200000, loss: 0.001531, epsilon: 0.010131, episode:  187\n",
      "frames: 269000, reward: -14.200000, loss: 0.001065, epsilon: 0.010126, episode:  187\n",
      "frames: 270000, reward: -14.200000, loss: 0.000901, epsilon: 0.010122, episode:  187\n",
      "frames: 271000, reward: -14.800000, loss: 0.000609, epsilon: 0.010118, episode:  188\n",
      "frames: 272000, reward: -14.800000, loss: 0.000873, epsilon: 0.010114, episode:  188\n",
      "frames: 273000, reward: -14.800000, loss: 0.000617, epsilon: 0.010111, episode:  188\n",
      "frames: 274000, reward: -14.800000, loss: 0.002510, epsilon: 0.010107, episode:  188\n",
      "frames: 275000, reward: -14.900000, loss: 0.001757, epsilon: 0.010103, episode:  189\n",
      "frames: 276000, reward: -14.900000, loss: 0.001492, epsilon: 0.010100, episode:  189\n",
      "frames: 277000, reward: -14.900000, loss: 0.001507, epsilon: 0.010097, episode:  189\n",
      "frames: 278000, reward: -14.900000, loss: 0.001285, epsilon: 0.010094, episode:  189\n",
      "frames: 279000, reward: -14.900000, loss: 0.002034, epsilon: 0.010091, episode:  190\n",
      "frames: 280000, reward: -14.900000, loss: 0.000519, epsilon: 0.010088, episode:  190\n",
      "frames: 281000, reward: -14.900000, loss: 0.001412, epsilon: 0.010085, episode:  190\n",
      "frames: 282000, reward: -14.900000, loss: 0.000669, epsilon: 0.010082, episode:  190\n",
      "frames: 283000, reward: -15.200000, loss: 0.001742, epsilon: 0.010079, episode:  191\n",
      "frames: 284000, reward: -15.200000, loss: 0.000970, epsilon: 0.010077, episode:  191\n",
      "frames: 285000, reward: -15.200000, loss: 0.002203, epsilon: 0.010074, episode:  191\n",
      "frames: 286000, reward: -15.200000, loss: 0.000821, epsilon: 0.010072, episode:  191\n",
      "frames: 287000, reward: -14.400000, loss: 0.000828, epsilon: 0.010069, episode:  192\n",
      "frames: 288000, reward: -14.400000, loss: 0.000874, epsilon: 0.010067, episode:  192\n",
      "frames: 289000, reward: -14.400000, loss: 0.000774, epsilon: 0.010065, episode:  192\n",
      "frames: 290000, reward: -14.700000, loss: 0.000800, epsilon: 0.010063, episode:  193\n",
      "frames: 291000, reward: -14.700000, loss: 0.002773, epsilon: 0.010061, episode:  193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 292000, reward: -14.700000, loss: 0.000545, epsilon: 0.010059, episode:  193\n",
      "frames: 293000, reward: -14.800000, loss: 0.000980, epsilon: 0.010057, episode:  194\n",
      "frames: 294000, reward: -14.800000, loss: 0.001253, epsilon: 0.010055, episode:  194\n",
      "frames: 295000, reward: -14.800000, loss: 0.000706, epsilon: 0.010053, episode:  194\n",
      "frames: 296000, reward: -14.800000, loss: 0.000583, epsilon: 0.010051, episode:  194\n",
      "frames: 297000, reward: -14.800000, loss: 0.000821, epsilon: 0.010050, episode:  195\n",
      "frames: 298000, reward: -14.800000, loss: 0.001941, epsilon: 0.010048, episode:  195\n",
      "frames: 299000, reward: -14.800000, loss: 0.001201, epsilon: 0.010046, episode:  195\n",
      "frames: 300000, reward: -14.800000, loss: 0.000831, epsilon: 0.010045, episode:  196\n",
      "frames: 301000, reward: -14.800000, loss: 0.000587, epsilon: 0.010043, episode:  196\n",
      "frames: 302000, reward: -14.800000, loss: 0.001449, epsilon: 0.010042, episode:  196\n",
      "frames: 303000, reward: -14.800000, loss: 0.002089, epsilon: 0.010041, episode:  196\n",
      "frames: 304000, reward: -14.300000, loss: 0.000830, epsilon: 0.010039, episode:  197\n",
      "frames: 305000, reward: -14.300000, loss: 0.001001, epsilon: 0.010038, episode:  197\n",
      "frames: 306000, reward: -14.300000, loss: 0.000841, epsilon: 0.010037, episode:  197\n",
      "frames: 307000, reward: -13.800000, loss: 0.002529, epsilon: 0.010036, episode:  198\n",
      "frames: 308000, reward: -13.800000, loss: 0.001106, epsilon: 0.010034, episode:  198\n",
      "frames: 309000, reward: -13.800000, loss: 0.000600, epsilon: 0.010033, episode:  198\n",
      "frames: 310000, reward: -13.800000, loss: 0.001009, epsilon: 0.010032, episode:  198\n",
      "frames: 311000, reward: -13.800000, loss: 0.000911, epsilon: 0.010031, episode:  198\n",
      "frames: 312000, reward: -13.300000, loss: 0.001078, epsilon: 0.010030, episode:  199\n",
      "frames: 313000, reward: -13.300000, loss: 0.000952, epsilon: 0.010029, episode:  199\n",
      "frames: 314000, reward: -13.300000, loss: 0.000567, epsilon: 0.010028, episode:  199\n",
      "frames: 315000, reward: -13.300000, loss: 0.001799, epsilon: 0.010027, episode:  199\n",
      "frames: 316000, reward: -13.300000, loss: 0.000794, epsilon: 0.010026, episode:  199\n",
      "frames: 317000, reward: -12.300000, loss: 0.000766, epsilon: 0.010026, episode:  200\n",
      "frames: 318000, reward: -12.300000, loss: 0.000648, epsilon: 0.010025, episode:  200\n",
      "frames: 319000, reward: -12.300000, loss: 0.001049, epsilon: 0.010024, episode:  200\n",
      "frames: 320000, reward: -12.300000, loss: 0.000328, epsilon: 0.010023, episode:  200\n",
      "frames: 321000, reward: -11.400000, loss: 0.000744, epsilon: 0.010022, episode:  201\n",
      "frames: 322000, reward: -11.400000, loss: 0.001179, epsilon: 0.010022, episode:  201\n",
      "frames: 323000, reward: -11.400000, loss: 0.000773, epsilon: 0.010021, episode:  201\n",
      "frames: 324000, reward: -11.400000, loss: 0.004404, epsilon: 0.010020, episode:  201\n",
      "frames: 325000, reward: -11.600000, loss: 0.001379, epsilon: 0.010020, episode:  202\n",
      "frames: 326000, reward: -11.600000, loss: 0.000884, epsilon: 0.010019, episode:  202\n",
      "frames: 327000, reward: -11.600000, loss: 0.000564, epsilon: 0.010018, episode:  202\n",
      "frames: 328000, reward: -11.600000, loss: 0.000923, epsilon: 0.010018, episode:  202\n",
      "frames: 329000, reward: -11.400000, loss: 0.000985, epsilon: 0.010017, episode:  203\n",
      "frames: 330000, reward: -11.400000, loss: 0.000468, epsilon: 0.010017, episode:  203\n",
      "frames: 331000, reward: -11.400000, loss: 0.002102, epsilon: 0.010016, episode:  203\n",
      "frames: 332000, reward: -11.200000, loss: 0.000408, epsilon: 0.010015, episode:  204\n",
      "frames: 333000, reward: -11.200000, loss: 0.000813, epsilon: 0.010015, episode:  204\n",
      "frames: 334000, reward: -11.200000, loss: 0.001161, epsilon: 0.010014, episode:  204\n",
      "frames: 335000, reward: -12.000000, loss: 0.001307, epsilon: 0.010014, episode:  205\n",
      "frames: 336000, reward: -12.000000, loss: 0.001244, epsilon: 0.010014, episode:  205\n",
      "frames: 337000, reward: -11.900000, loss: 0.000842, epsilon: 0.010013, episode:  206\n",
      "frames: 338000, reward: -11.900000, loss: 0.000703, epsilon: 0.010013, episode:  206\n",
      "frames: 339000, reward: -11.900000, loss: 0.001066, epsilon: 0.010012, episode:  206\n",
      "frames: 340000, reward: -11.900000, loss: 0.000703, epsilon: 0.010012, episode:  206\n",
      "frames: 341000, reward: -11.200000, loss: 0.000585, epsilon: 0.010011, episode:  207\n",
      "frames: 342000, reward: -11.200000, loss: 0.002493, epsilon: 0.010011, episode:  207\n",
      "frames: 343000, reward: -11.200000, loss: 0.001803, epsilon: 0.010011, episode:  207\n",
      "frames: 344000, reward: -11.700000, loss: 0.001268, epsilon: 0.010010, episode:  208\n",
      "frames: 345000, reward: -11.700000, loss: 0.000869, epsilon: 0.010010, episode:  208\n",
      "frames: 346000, reward: -11.700000, loss: 0.001540, epsilon: 0.010010, episode:  208\n",
      "frames: 347000, reward: -11.600000, loss: 0.001313, epsilon: 0.010009, episode:  209\n",
      "frames: 348000, reward: -11.600000, loss: 0.002190, epsilon: 0.010009, episode:  209\n",
      "frames: 349000, reward: -11.600000, loss: 0.001764, epsilon: 0.010009, episode:  209\n",
      "frames: 350000, reward: -12.600000, loss: 0.002615, epsilon: 0.010008, episode:  210\n",
      "frames: 351000, reward: -12.600000, loss: 0.001149, epsilon: 0.010008, episode:  210\n",
      "frames: 352000, reward: -12.600000, loss: 0.000771, epsilon: 0.010008, episode:  210\n",
      "frames: 353000, reward: -12.600000, loss: 0.000992, epsilon: 0.010008, episode:  210\n",
      "frames: 354000, reward: -12.000000, loss: 0.001696, epsilon: 0.010007, episode:  211\n",
      "frames: 355000, reward: -12.000000, loss: 0.000785, epsilon: 0.010007, episode:  211\n",
      "frames: 356000, reward: -12.000000, loss: 0.001295, epsilon: 0.010007, episode:  211\n",
      "frames: 357000, reward: -11.600000, loss: 0.001511, epsilon: 0.010007, episode:  212\n",
      "frames: 358000, reward: -11.600000, loss: 0.001094, epsilon: 0.010007, episode:  212\n",
      "frames: 359000, reward: -11.600000, loss: 0.000270, epsilon: 0.010006, episode:  212\n",
      "frames: 360000, reward: -11.600000, loss: 0.000892, epsilon: 0.010006, episode:  212\n",
      "frames: 361000, reward: -10.900000, loss: 0.001185, epsilon: 0.010006, episode:  213\n",
      "frames: 362000, reward: -10.900000, loss: 0.000627, epsilon: 0.010006, episode:  213\n",
      "frames: 363000, reward: -10.900000, loss: 0.001575, epsilon: 0.010006, episode:  213\n",
      "frames: 364000, reward: -10.200000, loss: 0.000960, epsilon: 0.010005, episode:  214\n",
      "frames: 365000, reward: -10.200000, loss: 0.000942, epsilon: 0.010005, episode:  214\n",
      "frames: 366000, reward: -10.200000, loss: 0.001808, epsilon: 0.010005, episode:  214\n",
      "frames: 367000, reward: -9.300000, loss: 0.001636, epsilon: 0.010005, episode:  215\n",
      "frames: 368000, reward: -9.300000, loss: 0.001159, epsilon: 0.010005, episode:  215\n",
      "frames: 369000, reward: -9.300000, loss: 0.000888, epsilon: 0.010005, episode:  215\n",
      "frames: 370000, reward: -8.700000, loss: 0.002736, epsilon: 0.010004, episode:  216\n",
      "frames: 371000, reward: -8.700000, loss: 0.002919, epsilon: 0.010004, episode:  216\n",
      "frames: 372000, reward: -8.700000, loss: 0.001049, epsilon: 0.010004, episode:  216\n",
      "frames: 373000, reward: -8.700000, loss: 0.001686, epsilon: 0.010004, episode:  216\n",
      "frames: 374000, reward: -8.500000, loss: 0.001976, epsilon: 0.010004, episode:  217\n",
      "frames: 375000, reward: -8.500000, loss: 0.001270, epsilon: 0.010004, episode:  217\n",
      "frames: 376000, reward: -8.500000, loss: 0.000851, epsilon: 0.010004, episode:  217\n",
      "frames: 377000, reward: -7.300000, loss: 0.002942, epsilon: 0.010003, episode:  218\n",
      "frames: 378000, reward: -7.300000, loss: 0.001068, epsilon: 0.010003, episode:  218\n",
      "frames: 379000, reward: -7.300000, loss: 0.001816, epsilon: 0.010003, episode:  218\n",
      "frames: 380000, reward: -7.300000, loss: 0.000679, epsilon: 0.010003, episode:  218\n",
      "frames: 381000, reward: -6.300000, loss: 0.002200, epsilon: 0.010003, episode:  219\n",
      "frames: 382000, reward: -6.300000, loss: 0.001230, epsilon: 0.010003, episode:  219\n",
      "frames: 383000, reward: -6.300000, loss: 0.001283, epsilon: 0.010003, episode:  219\n",
      "frames: 384000, reward: -6.300000, loss: 0.001655, epsilon: 0.010003, episode:  219\n",
      "frames: 385000, reward: -5.500000, loss: 0.002105, epsilon: 0.010003, episode:  220\n",
      "frames: 386000, reward: -5.500000, loss: 0.001179, epsilon: 0.010003, episode:  220\n",
      "frames: 387000, reward: -5.500000, loss: 0.003059, epsilon: 0.010002, episode:  220\n",
      "frames: 388000, reward: -4.900000, loss: 0.000735, epsilon: 0.010002, episode:  221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 389000, reward: -4.900000, loss: 0.001090, epsilon: 0.010002, episode:  221\n",
      "frames: 390000, reward: -4.900000, loss: 0.000782, epsilon: 0.010002, episode:  221\n",
      "frames: 391000, reward: -5.600000, loss: 0.000953, epsilon: 0.010002, episode:  222\n",
      "frames: 392000, reward: -5.600000, loss: 0.002407, epsilon: 0.010002, episode:  222\n",
      "frames: 393000, reward: -5.600000, loss: 0.001494, epsilon: 0.010002, episode:  222\n",
      "frames: 394000, reward: -5.900000, loss: 0.000922, epsilon: 0.010002, episode:  223\n",
      "frames: 395000, reward: -5.900000, loss: 0.000833, epsilon: 0.010002, episode:  223\n",
      "frames: 396000, reward: -5.900000, loss: 0.001406, epsilon: 0.010002, episode:  223\n",
      "frames: 397000, reward: -6.100000, loss: 0.002089, epsilon: 0.010002, episode:  224\n",
      "frames: 398000, reward: -6.100000, loss: 0.001714, epsilon: 0.010002, episode:  224\n",
      "frames: 399000, reward: -6.100000, loss: 0.001088, epsilon: 0.010002, episode:  224\n",
      "frames: 400000, reward: -6.100000, loss: 0.002339, epsilon: 0.010002, episode:  224\n",
      "frames: 401000, reward: -6.500000, loss: 0.000505, epsilon: 0.010002, episode:  225\n",
      "frames: 402000, reward: -6.500000, loss: 0.000623, epsilon: 0.010001, episode:  225\n",
      "frames: 403000, reward: -6.500000, loss: 0.001127, epsilon: 0.010001, episode:  225\n",
      "frames: 404000, reward: -6.500000, loss: 0.000894, epsilon: 0.010001, episode:  225\n",
      "frames: 405000, reward: -6.500000, loss: 0.304761, epsilon: 0.010001, episode:  225\n",
      "frames: 406000, reward: -5.300000, loss: 0.000687, epsilon: 0.010001, episode:  226\n",
      "frames: 407000, reward: -5.300000, loss: 0.000336, epsilon: 0.010001, episode:  226\n",
      "frames: 408000, reward: -5.300000, loss: 0.000606, epsilon: 0.010001, episode:  226\n",
      "frames: 409000, reward: -6.100000, loss: 0.001967, epsilon: 0.010001, episode:  227\n",
      "frames: 410000, reward: -6.100000, loss: 0.000646, epsilon: 0.010001, episode:  227\n",
      "frames: 411000, reward: -6.100000, loss: 0.000794, epsilon: 0.010001, episode:  227\n",
      "frames: 412000, reward: -6.800000, loss: 0.000906, epsilon: 0.010001, episode:  228\n",
      "frames: 413000, reward: -6.800000, loss: 0.000867, epsilon: 0.010001, episode:  228\n",
      "frames: 414000, reward: -8.400000, loss: 0.000752, epsilon: 0.010001, episode:  229\n",
      "frames: 415000, reward: -8.400000, loss: 0.000385, epsilon: 0.010001, episode:  229\n",
      "frames: 416000, reward: -8.400000, loss: 0.001400, epsilon: 0.010001, episode:  229\n",
      "frames: 417000, reward: -8.400000, loss: 0.000511, epsilon: 0.010001, episode:  229\n",
      "frames: 418000, reward: -8.400000, loss: 0.000493, epsilon: 0.010001, episode:  229\n",
      "frames: 419000, reward: -8.000000, loss: 0.001506, epsilon: 0.010001, episode:  230\n",
      "frames: 420000, reward: -8.000000, loss: 0.000986, epsilon: 0.010001, episode:  230\n",
      "frames: 421000, reward: -8.000000, loss: 0.000398, epsilon: 0.010001, episode:  230\n",
      "frames: 422000, reward: -9.500000, loss: 0.001176, epsilon: 0.010001, episode:  231\n",
      "frames: 423000, reward: -9.500000, loss: 0.001201, epsilon: 0.010001, episode:  231\n",
      "frames: 424000, reward: -9.500000, loss: 0.000349, epsilon: 0.010001, episode:  231\n",
      "frames: 425000, reward: -8.400000, loss: 0.000520, epsilon: 0.010001, episode:  232\n",
      "frames: 426000, reward: -8.400000, loss: 0.007799, epsilon: 0.010001, episode:  232\n",
      "frames: 427000, reward: -8.400000, loss: 0.001744, epsilon: 0.010001, episode:  232\n",
      "frames: 428000, reward: -8.400000, loss: 0.000549, epsilon: 0.010001, episode:  232\n",
      "frames: 429000, reward: -7.900000, loss: 0.000587, epsilon: 0.010001, episode:  233\n",
      "frames: 430000, reward: -7.900000, loss: 0.000760, epsilon: 0.010001, episode:  233\n",
      "frames: 431000, reward: -7.900000, loss: 0.000873, epsilon: 0.010001, episode:  234\n",
      "frames: 432000, reward: -7.900000, loss: 0.001897, epsilon: 0.010001, episode:  234\n",
      "frames: 433000, reward: -7.900000, loss: 0.001488, epsilon: 0.010001, episode:  234\n",
      "frames: 434000, reward: -7.900000, loss: 0.000909, epsilon: 0.010001, episode:  234\n",
      "frames: 435000, reward: -7.900000, loss: 0.001816, epsilon: 0.010000, episode:  234\n",
      "frames: 436000, reward: -6.800000, loss: 0.000990, epsilon: 0.010000, episode:  235\n",
      "frames: 437000, reward: -6.800000, loss: 0.001586, epsilon: 0.010000, episode:  235\n",
      "frames: 438000, reward: -6.800000, loss: 0.001234, epsilon: 0.010000, episode:  235\n",
      "frames: 439000, reward: -6.800000, loss: 0.001563, epsilon: 0.010000, episode:  235\n",
      "frames: 440000, reward: -7.000000, loss: 0.000685, epsilon: 0.010000, episode:  236\n",
      "frames: 441000, reward: -7.000000, loss: 0.001674, epsilon: 0.010000, episode:  236\n",
      "frames: 442000, reward: -7.000000, loss: 0.000558, epsilon: 0.010000, episode:  236\n",
      "frames: 443000, reward: -6.500000, loss: 0.001291, epsilon: 0.010000, episode:  237\n",
      "frames: 444000, reward: -6.500000, loss: 0.000796, epsilon: 0.010000, episode:  237\n",
      "frames: 445000, reward: -6.500000, loss: 0.001808, epsilon: 0.010000, episode:  237\n",
      "frames: 446000, reward: -6.500000, loss: 0.000498, epsilon: 0.010000, episode:  237\n",
      "frames: 447000, reward: -6.100000, loss: 0.001057, epsilon: 0.010000, episode:  238\n",
      "frames: 448000, reward: -6.100000, loss: 0.004046, epsilon: 0.010000, episode:  238\n",
      "frames: 449000, reward: -6.100000, loss: 0.000373, epsilon: 0.010000, episode:  238\n",
      "frames: 450000, reward: -5.600000, loss: 0.028449, epsilon: 0.010000, episode:  239\n",
      "frames: 451000, reward: -5.600000, loss: 0.001958, epsilon: 0.010000, episode:  239\n",
      "frames: 452000, reward: -5.600000, loss: 0.000874, epsilon: 0.010000, episode:  239\n",
      "frames: 453000, reward: -6.500000, loss: 0.000998, epsilon: 0.010000, episode:  240\n",
      "frames: 454000, reward: -6.500000, loss: 0.000637, epsilon: 0.010000, episode:  240\n",
      "frames: 455000, reward: -6.500000, loss: 0.000523, epsilon: 0.010000, episode:  240\n",
      "frames: 456000, reward: -6.400000, loss: 0.001789, epsilon: 0.010000, episode:  241\n",
      "frames: 457000, reward: -6.400000, loss: 0.000536, epsilon: 0.010000, episode:  241\n",
      "frames: 458000, reward: -6.400000, loss: 0.000558, epsilon: 0.010000, episode:  241\n",
      "frames: 459000, reward: -4.900000, loss: 0.001734, epsilon: 0.010000, episode:  242\n",
      "frames: 460000, reward: -4.900000, loss: 0.002894, epsilon: 0.010000, episode:  242\n",
      "frames: 461000, reward: -4.900000, loss: 0.000667, epsilon: 0.010000, episode:  242\n",
      "frames: 462000, reward: -4.900000, loss: 0.000748, epsilon: 0.010000, episode:  242\n",
      "frames: 463000, reward: -5.000000, loss: 0.000608, epsilon: 0.010000, episode:  243\n",
      "frames: 464000, reward: -5.000000, loss: 0.000819, epsilon: 0.010000, episode:  243\n",
      "frames: 465000, reward: -5.000000, loss: 0.000742, epsilon: 0.010000, episode:  243\n",
      "frames: 466000, reward: -5.000000, loss: 0.000541, epsilon: 0.010000, episode:  243\n",
      "frames: 467000, reward: -4.200000, loss: 0.000513, epsilon: 0.010000, episode:  244\n",
      "frames: 468000, reward: -4.200000, loss: 0.000432, epsilon: 0.010000, episode:  244\n",
      "frames: 469000, reward: -4.200000, loss: 0.000421, epsilon: 0.010000, episode:  244\n",
      "frames: 470000, reward: -2.800000, loss: 0.000814, epsilon: 0.010000, episode:  245\n",
      "frames: 471000, reward: -2.800000, loss: 0.001097, epsilon: 0.010000, episode:  245\n",
      "frames: 472000, reward: -1.500000, loss: 0.001068, epsilon: 0.010000, episode:  246\n",
      "frames: 473000, reward: -1.500000, loss: 0.000600, epsilon: 0.010000, episode:  246\n",
      "frames: 474000, reward: -1.500000, loss: 0.000475, epsilon: 0.010000, episode:  246\n",
      "frames: 475000, reward: -1.200000, loss: 0.000822, epsilon: 0.010000, episode:  247\n",
      "frames: 476000, reward: -1.200000, loss: 0.000658, epsilon: 0.010000, episode:  247\n",
      "frames: 477000, reward: 0.900000, loss: 0.000962, epsilon: 0.010000, episode:  248\n",
      "frames: 478000, reward: 0.900000, loss: 0.001594, epsilon: 0.010000, episode:  248\n",
      "frames: 479000, reward: 0.900000, loss: 0.000478, epsilon: 0.010000, episode:  248\n",
      "frames: 480000, reward: 3.300000, loss: 0.000313, epsilon: 0.010000, episode:  249\n",
      "frames: 481000, reward: 3.300000, loss: 0.000746, epsilon: 0.010000, episode:  249\n",
      "frames: 482000, reward: 5.900000, loss: 0.000452, epsilon: 0.010000, episode:  250\n",
      "frames: 483000, reward: 5.900000, loss: 0.001610, epsilon: 0.010000, episode:  250\n",
      "frames: 484000, reward: 5.900000, loss: 0.000730, epsilon: 0.010000, episode:  250\n",
      "frames: 485000, reward: 7.800000, loss: 0.002011, epsilon: 0.010000, episode:  251\n",
      "frames: 486000, reward: 7.800000, loss: 0.000436, epsilon: 0.010000, episode:  251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 487000, reward: 7.800000, loss: 0.001834, epsilon: 0.010000, episode:  251\n",
      "frames: 488000, reward: 8.100000, loss: 0.000863, epsilon: 0.010000, episode:  252\n",
      "frames: 489000, reward: 8.100000, loss: 0.000608, epsilon: 0.010000, episode:  252\n",
      "frames: 490000, reward: 9.700000, loss: 0.000785, epsilon: 0.010000, episode:  253\n",
      "frames: 491000, reward: 9.700000, loss: 0.001268, epsilon: 0.010000, episode:  253\n",
      "frames: 492000, reward: 11.500000, loss: 0.000906, epsilon: 0.010000, episode:  254\n",
      "frames: 493000, reward: 11.500000, loss: 0.000493, epsilon: 0.010000, episode:  254\n",
      "frames: 494000, reward: 11.500000, loss: 0.000647, epsilon: 0.010000, episode:  254\n",
      "frames: 495000, reward: 11.300000, loss: 0.000766, epsilon: 0.010000, episode:  255\n",
      "frames: 496000, reward: 11.300000, loss: 0.000476, epsilon: 0.010000, episode:  255\n",
      "frames: 497000, reward: 11.300000, loss: 0.000363, epsilon: 0.010000, episode:  255\n",
      "frames: 498000, reward: 10.800000, loss: 0.001374, epsilon: 0.010000, episode:  256\n",
      "frames: 499000, reward: 10.800000, loss: 0.000305, epsilon: 0.010000, episode:  256\n",
      "frames: 500000, reward: 12.400000, loss: 0.021605, epsilon: 0.010000, episode:  257\n",
      "frames: 501000, reward: 12.400000, loss: 0.000494, epsilon: 0.010000, episode:  257\n",
      "frames: 502000, reward: 12.400000, loss: 0.000683, epsilon: 0.010000, episode:  257\n",
      "frames: 503000, reward: 12.400000, loss: 0.000960, epsilon: 0.010000, episode:  257\n",
      "frames: 504000, reward: 12.400000, loss: 0.000532, epsilon: 0.010000, episode:  257\n",
      "frames: 505000, reward: 11.700000, loss: 0.002197, epsilon: 0.010000, episode:  258\n",
      "frames: 506000, reward: 11.700000, loss: 0.000839, epsilon: 0.010000, episode:  258\n",
      "frames: 507000, reward: 12.000000, loss: 0.000341, epsilon: 0.010000, episode:  259\n",
      "frames: 508000, reward: 12.000000, loss: 0.000542, epsilon: 0.010000, episode:  259\n",
      "frames: 509000, reward: 11.700000, loss: 0.000812, epsilon: 0.010000, episode:  260\n",
      "frames: 510000, reward: 11.700000, loss: 0.000842, epsilon: 0.010000, episode:  260\n",
      "frames: 511000, reward: 11.700000, loss: 0.000578, epsilon: 0.010000, episode:  260\n",
      "frames: 512000, reward: 11.900000, loss: 0.000704, epsilon: 0.010000, episode:  261\n",
      "frames: 513000, reward: 11.900000, loss: 0.001123, epsilon: 0.010000, episode:  261\n",
      "frames: 514000, reward: 12.000000, loss: 0.002232, epsilon: 0.010000, episode:  262\n",
      "frames: 515000, reward: 12.000000, loss: 0.000236, epsilon: 0.010000, episode:  262\n",
      "frames: 516000, reward: 12.000000, loss: 0.000372, epsilon: 0.010000, episode:  262\n",
      "frames: 517000, reward: 12.000000, loss: 0.002085, epsilon: 0.010000, episode:  263\n",
      "frames: 518000, reward: 12.000000, loss: 0.001170, epsilon: 0.010000, episode:  263\n",
      "frames: 519000, reward: 12.000000, loss: 0.000242, epsilon: 0.010000, episode:  263\n",
      "frames: 520000, reward: 11.400000, loss: 0.000401, epsilon: 0.010000, episode:  264\n",
      "frames: 521000, reward: 11.400000, loss: 0.000929, epsilon: 0.010000, episode:  264\n",
      "frames: 522000, reward: 11.800000, loss: 0.000389, epsilon: 0.010000, episode:  265\n",
      "frames: 523000, reward: 11.800000, loss: 0.000269, epsilon: 0.010000, episode:  265\n",
      "frames: 524000, reward: 11.800000, loss: 0.000424, epsilon: 0.010000, episode:  265\n",
      "frames: 525000, reward: 11.900000, loss: 0.000738, epsilon: 0.010000, episode:  266\n",
      "frames: 526000, reward: 11.900000, loss: 0.000517, epsilon: 0.010000, episode:  266\n",
      "frames: 527000, reward: 12.600000, loss: 0.000295, epsilon: 0.010000, episode:  267\n",
      "frames: 528000, reward: 12.600000, loss: 0.000935, epsilon: 0.010000, episode:  267\n",
      "frames: 529000, reward: 13.700000, loss: 0.000332, epsilon: 0.010000, episode:  268\n",
      "frames: 530000, reward: 13.700000, loss: 0.000739, epsilon: 0.010000, episode:  268\n",
      "frames: 531000, reward: 14.100000, loss: 0.000145, epsilon: 0.010000, episode:  269\n",
      "frames: 532000, reward: 14.100000, loss: 0.000213, epsilon: 0.010000, episode:  269\n",
      "frames: 533000, reward: 14.100000, loss: 0.000525, epsilon: 0.010000, episode:  269\n",
      "frames: 534000, reward: 13.500000, loss: 0.000565, epsilon: 0.010000, episode:  270\n",
      "frames: 535000, reward: 13.500000, loss: 0.000153, epsilon: 0.010000, episode:  270\n",
      "frames: 536000, reward: 14.400000, loss: 0.000680, epsilon: 0.010000, episode:  271\n",
      "frames: 537000, reward: 14.400000, loss: 0.000240, epsilon: 0.010000, episode:  271\n",
      "frames: 538000, reward: 14.400000, loss: 0.000688, epsilon: 0.010000, episode:  271\n",
      "frames: 539000, reward: 13.400000, loss: 0.000777, epsilon: 0.010000, episode:  272\n",
      "frames: 540000, reward: 13.400000, loss: 0.000529, epsilon: 0.010000, episode:  272\n",
      "frames: 541000, reward: 13.600000, loss: 0.000381, epsilon: 0.010000, episode:  273\n",
      "frames: 542000, reward: 13.600000, loss: 0.000217, epsilon: 0.010000, episode:  273\n",
      "frames: 543000, reward: 14.300000, loss: 0.000785, epsilon: 0.010000, episode:  274\n",
      "frames: 544000, reward: 14.300000, loss: 0.000620, epsilon: 0.010000, episode:  274\n",
      "frames: 545000, reward: 14.800000, loss: 0.000299, epsilon: 0.010000, episode:  275\n",
      "frames: 546000, reward: 14.800000, loss: 0.001321, epsilon: 0.010000, episode:  275\n",
      "frames: 547000, reward: 15.400000, loss: 0.000680, epsilon: 0.010000, episode:  276\n",
      "frames: 548000, reward: 15.400000, loss: 0.000552, epsilon: 0.010000, episode:  276\n",
      "frames: 549000, reward: 15.400000, loss: 0.000543, epsilon: 0.010000, episode:  276\n",
      "frames: 550000, reward: 14.400000, loss: 0.000556, epsilon: 0.010000, episode:  277\n",
      "frames: 551000, reward: 14.400000, loss: 0.000297, epsilon: 0.010000, episode:  277\n",
      "frames: 552000, reward: 14.600000, loss: 0.000514, epsilon: 0.010000, episode:  278\n",
      "frames: 553000, reward: 14.600000, loss: 0.000754, epsilon: 0.010000, episode:  278\n",
      "frames: 554000, reward: 14.100000, loss: 0.000963, epsilon: 0.010000, episode:  279\n",
      "frames: 555000, reward: 14.100000, loss: 0.000514, epsilon: 0.010000, episode:  279\n",
      "frames: 556000, reward: 14.900000, loss: 0.000402, epsilon: 0.010000, episode:  280\n",
      "frames: 557000, reward: 14.900000, loss: 0.000200, epsilon: 0.010000, episode:  280\n",
      "frames: 558000, reward: 14.900000, loss: 0.001150, epsilon: 0.010000, episode:  280\n",
      "frames: 559000, reward: 14.900000, loss: 0.000694, epsilon: 0.010000, episode:  280\n",
      "frames: 560000, reward: 13.700000, loss: 0.000273, epsilon: 0.010000, episode:  281\n",
      "frames: 561000, reward: 15.100000, loss: 0.000679, epsilon: 0.010000, episode:  282\n",
      "frames: 562000, reward: 15.100000, loss: 0.000350, epsilon: 0.010000, episode:  282\n",
      "frames: 563000, reward: 15.100000, loss: 0.620694, epsilon: 0.010000, episode:  282\n",
      "frames: 564000, reward: 15.400000, loss: 0.000617, epsilon: 0.010000, episode:  283\n",
      "frames: 565000, reward: 15.400000, loss: 0.000481, epsilon: 0.010000, episode:  283\n",
      "frames: 566000, reward: 14.600000, loss: 0.000717, epsilon: 0.010000, episode:  284\n",
      "frames: 567000, reward: 14.600000, loss: 0.000490, epsilon: 0.010000, episode:  284\n",
      "frames: 568000, reward: 14.600000, loss: 0.001182, epsilon: 0.010000, episode:  284\n",
      "frames: 569000, reward: 14.400000, loss: 0.000186, epsilon: 0.010000, episode:  285\n",
      "frames: 570000, reward: 14.700000, loss: 0.000288, epsilon: 0.010000, episode:  286\n",
      "frames: 571000, reward: 14.700000, loss: 0.000324, epsilon: 0.010000, episode:  286\n",
      "frames: 572000, reward: 15.800000, loss: 0.000365, epsilon: 0.010000, episode:  287\n",
      "frames: 573000, reward: 15.800000, loss: 0.000359, epsilon: 0.010000, episode:  287\n",
      "frames: 574000, reward: 15.800000, loss: 0.000419, epsilon: 0.010000, episode:  288\n",
      "frames: 575000, reward: 15.800000, loss: 0.000391, epsilon: 0.010000, episode:  288\n",
      "frames: 576000, reward: 16.000000, loss: 0.000598, epsilon: 0.010000, episode:  289\n",
      "frames: 577000, reward: 16.000000, loss: 0.000517, epsilon: 0.010000, episode:  289\n",
      "frames: 578000, reward: 16.300000, loss: 0.000334, epsilon: 0.010000, episode:  290\n",
      "frames: 579000, reward: 16.300000, loss: 0.000262, epsilon: 0.010000, episode:  290\n",
      "frames: 580000, reward: 17.500000, loss: 0.000206, epsilon: 0.010000, episode:  291\n",
      "frames: 581000, reward: 17.500000, loss: 0.000323, epsilon: 0.010000, episode:  291\n",
      "frames: 582000, reward: 17.300000, loss: 0.000207, epsilon: 0.010000, episode:  292\n",
      "frames: 583000, reward: 17.300000, loss: 0.000303, epsilon: 0.010000, episode:  292\n",
      "frames: 584000, reward: 17.300000, loss: 0.000439, epsilon: 0.010000, episode:  292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 585000, reward: 16.900000, loss: 0.000772, epsilon: 0.010000, episode:  293\n",
      "frames: 586000, reward: 16.900000, loss: 0.000270, epsilon: 0.010000, episode:  293\n",
      "frames: 587000, reward: 17.900000, loss: 0.000207, epsilon: 0.010000, episode:  294\n",
      "frames: 588000, reward: 17.900000, loss: 0.000261, epsilon: 0.010000, episode:  294\n",
      "frames: 589000, reward: 18.100000, loss: 0.000270, epsilon: 0.010000, episode:  295\n",
      "frames: 590000, reward: 18.100000, loss: 0.000272, epsilon: 0.010000, episode:  295\n",
      "frames: 591000, reward: 18.000000, loss: 0.001120, epsilon: 0.010000, episode:  296\n",
      "frames: 592000, reward: 18.000000, loss: 0.000251, epsilon: 0.010000, episode:  296\n",
      "frames: 593000, reward: 17.200000, loss: 0.000366, epsilon: 0.010000, episode:  297\n",
      "frames: 594000, reward: 17.200000, loss: 0.000131, epsilon: 0.010000, episode:  297\n",
      "frames: 595000, reward: 17.300000, loss: 0.000642, epsilon: 0.010000, episode:  298\n",
      "frames: 596000, reward: 17.300000, loss: 0.000226, epsilon: 0.010000, episode:  298\n",
      "frames: 597000, reward: 17.400000, loss: 0.000088, epsilon: 0.010000, episode:  299\n",
      "frames: 598000, reward: 17.400000, loss: 0.000179, epsilon: 0.010000, episode:  299\n",
      "frames: 599000, reward: 17.300000, loss: 0.000219, epsilon: 0.010000, episode:  300\n",
      "frames: 600000, reward: 17.300000, loss: 0.000169, epsilon: 0.010000, episode:  300\n",
      "frames: 601000, reward: 17.100000, loss: 0.000464, epsilon: 0.010000, episode:  301\n",
      "frames: 602000, reward: 17.300000, loss: 0.000390, epsilon: 0.010000, episode:  302\n",
      "frames: 603000, reward: 17.300000, loss: 0.000256, epsilon: 0.010000, episode:  302\n",
      "frames: 604000, reward: 17.300000, loss: 0.000704, epsilon: 0.010000, episode:  302\n",
      "frames: 605000, reward: 17.600000, loss: 0.000123, epsilon: 0.010000, episode:  303\n",
      "frames: 606000, reward: 17.600000, loss: 0.000219, epsilon: 0.010000, episode:  303\n",
      "frames: 607000, reward: 16.900000, loss: 0.000287, epsilon: 0.010000, episode:  304\n",
      "frames: 608000, reward: 16.900000, loss: 0.000577, epsilon: 0.010000, episode:  304\n",
      "frames: 609000, reward: 16.900000, loss: 0.000927, epsilon: 0.010000, episode:  304\n",
      "frames: 610000, reward: 16.600000, loss: 0.001696, epsilon: 0.010000, episode:  305\n",
      "frames: 611000, reward: 16.600000, loss: 0.000702, epsilon: 0.010000, episode:  305\n",
      "frames: 612000, reward: 16.600000, loss: 0.000713, epsilon: 0.010000, episode:  305\n",
      "frames: 613000, reward: 16.000000, loss: 0.000159, epsilon: 0.010000, episode:  306\n",
      "frames: 614000, reward: 16.900000, loss: 0.000197, epsilon: 0.010000, episode:  307\n",
      "frames: 615000, reward: 16.900000, loss: 0.000255, epsilon: 0.010000, episode:  307\n",
      "frames: 616000, reward: 16.600000, loss: 0.000824, epsilon: 0.010000, episode:  308\n",
      "frames: 617000, reward: 16.600000, loss: 0.000368, epsilon: 0.010000, episode:  308\n",
      "frames: 618000, reward: 16.900000, loss: 0.000343, epsilon: 0.010000, episode:  309\n",
      "frames: 619000, reward: 16.900000, loss: 0.000296, epsilon: 0.010000, episode:  309\n",
      "frames: 620000, reward: 17.000000, loss: 0.000177, epsilon: 0.010000, episode:  310\n",
      "frames: 621000, reward: 17.000000, loss: 0.000233, epsilon: 0.010000, episode:  310\n",
      "frames: 622000, reward: 17.000000, loss: 0.000325, epsilon: 0.010000, episode:  311\n",
      "frames: 623000, reward: 17.000000, loss: 0.000176, epsilon: 0.010000, episode:  311\n",
      "frames: 624000, reward: 17.000000, loss: 0.000437, epsilon: 0.010000, episode:  312\n",
      "frames: 625000, reward: 17.000000, loss: 0.001158, epsilon: 0.010000, episode:  312\n",
      "frames: 626000, reward: 17.200000, loss: 0.001319, epsilon: 0.010000, episode:  313\n",
      "frames: 627000, reward: 17.200000, loss: 0.000675, epsilon: 0.010000, episode:  313\n",
      "frames: 628000, reward: 17.900000, loss: 0.000252, epsilon: 0.010000, episode:  314\n",
      "frames: 629000, reward: 17.900000, loss: 0.000743, epsilon: 0.010000, episode:  314\n",
      "frames: 630000, reward: 17.900000, loss: 0.000338, epsilon: 0.010000, episode:  315\n",
      "frames: 631000, reward: 17.900000, loss: 0.000260, epsilon: 0.010000, episode:  315\n",
      "frames: 632000, reward: 18.500000, loss: 0.000399, epsilon: 0.010000, episode:  316\n",
      "frames: 633000, reward: 18.500000, loss: 0.000523, epsilon: 0.010000, episode:  316\n",
      "frames: 634000, reward: 18.600000, loss: 0.000285, epsilon: 0.010000, episode:  317\n",
      "frames: 635000, reward: 18.800000, loss: 0.002283, epsilon: 0.010000, episode:  318\n",
      "frames: 636000, reward: 18.800000, loss: 0.000191, epsilon: 0.010000, episode:  318\n",
      "frames: 637000, reward: 18.800000, loss: 0.000125, epsilon: 0.010000, episode:  318\n",
      "frames: 638000, reward: 18.300000, loss: 0.000354, epsilon: 0.010000, episode:  319\n",
      "frames: 639000, reward: 18.300000, loss: 0.000220, epsilon: 0.010000, episode:  319\n",
      "frames: 640000, reward: 18.300000, loss: 0.000186, epsilon: 0.010000, episode:  320\n",
      "frames: 641000, reward: 18.300000, loss: 0.000281, epsilon: 0.010000, episode:  320\n",
      "frames: 642000, reward: 18.200000, loss: 0.000682, epsilon: 0.010000, episode:  321\n",
      "frames: 643000, reward: 18.200000, loss: 0.018578, epsilon: 0.010000, episode:  322\n",
      "frames: 644000, reward: 18.200000, loss: 0.000225, epsilon: 0.010000, episode:  322\n",
      "frames: 645000, reward: 18.300000, loss: 0.000173, epsilon: 0.010000, episode:  323\n",
      "frames: 646000, reward: 18.300000, loss: 0.000372, epsilon: 0.010000, episode:  323\n",
      "frames: 647000, reward: 18.500000, loss: 0.000258, epsilon: 0.010000, episode:  324\n",
      "frames: 648000, reward: 18.500000, loss: 0.000323, epsilon: 0.010000, episode:  324\n",
      "frames: 649000, reward: 18.500000, loss: 0.000311, epsilon: 0.010000, episode:  325\n",
      "frames: 650000, reward: 18.500000, loss: 0.000089, epsilon: 0.010000, episode:  325\n",
      "frames: 651000, reward: 18.500000, loss: 0.000489, epsilon: 0.010000, episode:  326\n",
      "frames: 652000, reward: 18.500000, loss: 0.000747, epsilon: 0.010000, episode:  326\n",
      "frames: 653000, reward: 18.500000, loss: 0.001184, epsilon: 0.010000, episode:  326\n",
      "frames: 654000, reward: 17.600000, loss: 0.000220, epsilon: 0.010000, episode:  327\n",
      "frames: 655000, reward: 17.600000, loss: 0.000268, epsilon: 0.010000, episode:  327\n",
      "frames: 656000, reward: 17.600000, loss: 0.000893, epsilon: 0.010000, episode:  328\n",
      "frames: 657000, reward: 18.200000, loss: 0.000265, epsilon: 0.010000, episode:  329\n",
      "frames: 658000, reward: 18.200000, loss: 0.000269, epsilon: 0.010000, episode:  329\n",
      "frames: 659000, reward: 18.200000, loss: 0.000302, epsilon: 0.010000, episode:  330\n",
      "frames: 660000, reward: 18.200000, loss: 0.000284, epsilon: 0.010000, episode:  330\n",
      "frames: 661000, reward: 18.700000, loss: 0.000166, epsilon: 0.010000, episode:  331\n",
      "frames: 662000, reward: 18.700000, loss: 0.000670, epsilon: 0.010000, episode:  331\n",
      "frames: 663000, reward: 18.700000, loss: 0.000153, epsilon: 0.010000, episode:  331\n",
      "frames: 664000, reward: 17.700000, loss: 0.000103, epsilon: 0.010000, episode:  332\n",
      "frames: 665000, reward: 17.900000, loss: 0.001950, epsilon: 0.010000, episode:  333\n",
      "frames: 666000, reward: 17.900000, loss: 0.002186, epsilon: 0.010000, episode:  333\n",
      "frames: 667000, reward: 17.900000, loss: 0.000732, epsilon: 0.010000, episode:  333\n",
      "frames: 668000, reward: 17.000000, loss: 0.001656, epsilon: 0.010000, episode:  334\n",
      "frames: 669000, reward: 17.000000, loss: 0.000667, epsilon: 0.010000, episode:  334\n",
      "frames: 670000, reward: 17.100000, loss: 0.000244, epsilon: 0.010000, episode:  335\n",
      "frames: 671000, reward: 17.100000, loss: 0.000244, epsilon: 0.010000, episode:  335\n",
      "frames: 672000, reward: 17.200000, loss: 0.000213, epsilon: 0.010000, episode:  336\n",
      "frames: 673000, reward: 17.200000, loss: 0.000200, epsilon: 0.010000, episode:  336\n",
      "frames: 674000, reward: 18.100000, loss: 0.000186, epsilon: 0.010000, episode:  337\n",
      "frames: 675000, reward: 18.100000, loss: 0.001014, epsilon: 0.010000, episode:  337\n",
      "frames: 676000, reward: 17.900000, loss: 0.000281, epsilon: 0.010000, episode:  338\n",
      "frames: 677000, reward: 17.700000, loss: 0.000831, epsilon: 0.010000, episode:  339\n",
      "frames: 678000, reward: 17.700000, loss: 0.000226, epsilon: 0.010000, episode:  339\n",
      "frames: 679000, reward: 17.600000, loss: 0.000255, epsilon: 0.010000, episode:  340\n",
      "frames: 680000, reward: 17.600000, loss: 0.000090, epsilon: 0.010000, episode:  340\n",
      "frames: 681000, reward: 17.300000, loss: 0.000506, epsilon: 0.010000, episode:  341\n",
      "frames: 682000, reward: 17.300000, loss: 0.000461, epsilon: 0.010000, episode:  341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 683000, reward: 18.300000, loss: 0.000149, epsilon: 0.010000, episode:  342\n",
      "frames: 684000, reward: 18.300000, loss: 0.000097, epsilon: 0.010000, episode:  342\n",
      "frames: 685000, reward: 18.300000, loss: 0.000306, epsilon: 0.010000, episode:  343\n",
      "frames: 686000, reward: 19.000000, loss: 0.000221, epsilon: 0.010000, episode:  344\n",
      "frames: 687000, reward: 19.000000, loss: 0.000111, epsilon: 0.010000, episode:  344\n",
      "frames: 688000, reward: 19.300000, loss: 0.000112, epsilon: 0.010000, episode:  345\n",
      "frames: 689000, reward: 19.300000, loss: 0.000155, epsilon: 0.010000, episode:  345\n",
      "frames: 690000, reward: 19.100000, loss: 0.000112, epsilon: 0.010000, episode:  346\n",
      "frames: 691000, reward: 19.100000, loss: 0.000197, epsilon: 0.010000, episode:  346\n",
      "frames: 692000, reward: 18.800000, loss: 0.000279, epsilon: 0.010000, episode:  347\n",
      "frames: 693000, reward: 18.800000, loss: 0.000122, epsilon: 0.010000, episode:  347\n",
      "frames: 694000, reward: 19.000000, loss: 0.000247, epsilon: 0.010000, episode:  348\n",
      "frames: 695000, reward: 19.000000, loss: 0.000261, epsilon: 0.010000, episode:  348\n",
      "frames: 696000, reward: 18.200000, loss: 0.000516, epsilon: 0.010000, episode:  349\n",
      "frames: 697000, reward: 18.200000, loss: 0.000304, epsilon: 0.010000, episode:  349\n",
      "frames: 698000, reward: 18.200000, loss: 0.000335, epsilon: 0.010000, episode:  349\n",
      "frames: 699000, reward: 17.800000, loss: 0.000326, epsilon: 0.010000, episode:  350\n",
      "frames: 700000, reward: 17.900000, loss: 0.000349, epsilon: 0.010000, episode:  351\n",
      "frames: 701000, reward: 17.900000, loss: 0.000345, epsilon: 0.010000, episode:  351\n",
      "frames: 702000, reward: 17.900000, loss: 0.001248, epsilon: 0.010000, episode:  351\n",
      "frames: 703000, reward: 17.500000, loss: 0.000268, epsilon: 0.010000, episode:  352\n",
      "frames: 704000, reward: 17.500000, loss: 0.000159, epsilon: 0.010000, episode:  353\n",
      "frames: 705000, reward: 17.500000, loss: 0.000212, epsilon: 0.010000, episode:  353\n",
      "frames: 706000, reward: 17.200000, loss: 0.000353, epsilon: 0.010000, episode:  354\n",
      "frames: 707000, reward: 17.200000, loss: 0.000186, epsilon: 0.010000, episode:  354\n",
      "frames: 708000, reward: 17.200000, loss: 0.000346, epsilon: 0.010000, episode:  355\n",
      "frames: 709000, reward: 17.200000, loss: 0.000263, epsilon: 0.010000, episode:  355\n",
      "frames: 710000, reward: 17.400000, loss: 0.000371, epsilon: 0.010000, episode:  356\n",
      "frames: 711000, reward: 17.700000, loss: 0.000139, epsilon: 0.010000, episode:  357\n",
      "frames: 712000, reward: 17.700000, loss: 0.000110, epsilon: 0.010000, episode:  357\n",
      "frames: 713000, reward: 17.600000, loss: 0.000256, epsilon: 0.010000, episode:  358\n",
      "frames: 714000, reward: 17.600000, loss: 0.000119, epsilon: 0.010000, episode:  358\n",
      "frames: 715000, reward: 18.500000, loss: 0.000276, epsilon: 0.010000, episode:  359\n",
      "frames: 716000, reward: 18.500000, loss: 0.000209, epsilon: 0.010000, episode:  359\n",
      "frames: 717000, reward: 19.100000, loss: 0.000317, epsilon: 0.010000, episode:  360\n",
      "frames: 718000, reward: 19.100000, loss: 0.000114, epsilon: 0.010000, episode:  360\n",
      "frames: 719000, reward: 18.600000, loss: 0.002780, epsilon: 0.010000, episode:  361\n",
      "frames: 720000, reward: 18.600000, loss: 0.001999, epsilon: 0.010000, episode:  361\n",
      "frames: 721000, reward: 18.600000, loss: 0.000174, epsilon: 0.010000, episode:  362\n",
      "frames: 722000, reward: 18.600000, loss: 0.000269, epsilon: 0.010000, episode:  362\n",
      "frames: 723000, reward: 18.600000, loss: 0.000383, epsilon: 0.010000, episode:  363\n",
      "frames: 724000, reward: 18.600000, loss: 0.000098, epsilon: 0.010000, episode:  363\n",
      "frames: 725000, reward: 18.900000, loss: 0.000162, epsilon: 0.010000, episode:  364\n",
      "frames: 726000, reward: 18.900000, loss: 0.000352, epsilon: 0.010000, episode:  365\n",
      "frames: 727000, reward: 18.900000, loss: 0.000502, epsilon: 0.010000, episode:  365\n",
      "frames: 728000, reward: 18.700000, loss: 0.000531, epsilon: 0.010000, episode:  366\n",
      "frames: 729000, reward: 18.700000, loss: 0.000162, epsilon: 0.010000, episode:  366\n",
      "frames: 730000, reward: 18.600000, loss: 0.000144, epsilon: 0.010000, episode:  367\n",
      "frames: 731000, reward: 18.600000, loss: 0.000081, epsilon: 0.010000, episode:  367\n",
      "frames: 732000, reward: 18.900000, loss: 0.000117, epsilon: 0.010000, episode:  368\n",
      "frames: 733000, reward: 18.700000, loss: 0.000159, epsilon: 0.010000, episode:  369\n",
      "frames: 734000, reward: 18.700000, loss: 0.000914, epsilon: 0.010000, episode:  369\n",
      "frames: 735000, reward: 18.600000, loss: 0.000221, epsilon: 0.010000, episode:  370\n",
      "frames: 736000, reward: 18.600000, loss: 0.000197, epsilon: 0.010000, episode:  370\n",
      "frames: 737000, reward: 19.200000, loss: 0.002232, epsilon: 0.010000, episode:  371\n",
      "frames: 738000, reward: 19.200000, loss: 0.000103, epsilon: 0.010000, episode:  371\n",
      "frames: 739000, reward: 19.400000, loss: 0.000333, epsilon: 0.010000, episode:  372\n",
      "frames: 740000, reward: 19.400000, loss: 0.000601, epsilon: 0.010000, episode:  372\n",
      "frames: 741000, reward: 18.600000, loss: 0.009241, epsilon: 0.010000, episode:  373\n",
      "frames: 742000, reward: 18.600000, loss: 0.000282, epsilon: 0.010000, episode:  373\n",
      "frames: 743000, reward: 18.700000, loss: 0.000180, epsilon: 0.010000, episode:  374\n",
      "frames: 744000, reward: 18.700000, loss: 0.000318, epsilon: 0.010000, episode:  374\n",
      "frames: 745000, reward: 18.700000, loss: 0.000133, epsilon: 0.010000, episode:  375\n",
      "frames: 746000, reward: 18.700000, loss: 0.000279, epsilon: 0.010000, episode:  375\n",
      "frames: 747000, reward: 18.900000, loss: 0.001257, epsilon: 0.010000, episode:  376\n",
      "frames: 748000, reward: 18.900000, loss: 0.000148, epsilon: 0.010000, episode:  376\n",
      "frames: 749000, reward: 18.900000, loss: 0.000119, epsilon: 0.010000, episode:  377\n",
      "frames: 750000, reward: 18.800000, loss: 0.000202, epsilon: 0.010000, episode:  378\n",
      "frames: 751000, reward: 18.800000, loss: 0.000099, epsilon: 0.010000, episode:  378\n",
      "frames: 752000, reward: 18.900000, loss: 0.000082, epsilon: 0.010000, episode:  379\n",
      "frames: 753000, reward: 18.900000, loss: 0.000178, epsilon: 0.010000, episode:  379\n",
      "frames: 754000, reward: 18.600000, loss: 0.000283, epsilon: 0.010000, episode:  380\n",
      "frames: 755000, reward: 18.600000, loss: 0.000621, epsilon: 0.010000, episode:  380\n",
      "frames: 756000, reward: 18.500000, loss: 0.000272, epsilon: 0.010000, episode:  381\n",
      "frames: 757000, reward: 18.500000, loss: 0.000091, epsilon: 0.010000, episode:  381\n",
      "frames: 758000, reward: 18.300000, loss: 0.000214, epsilon: 0.010000, episode:  382\n",
      "frames: 759000, reward: 18.300000, loss: 0.000185, epsilon: 0.010000, episode:  382\n",
      "frames: 760000, reward: 19.000000, loss: 0.000107, epsilon: 0.010000, episode:  383\n",
      "frames: 761000, reward: 19.000000, loss: 0.000107, epsilon: 0.010000, episode:  383\n",
      "frames: 762000, reward: 18.800000, loss: 0.000241, epsilon: 0.010000, episode:  384\n",
      "frames: 763000, reward: 18.800000, loss: 0.001137, epsilon: 0.010000, episode:  384\n",
      "frames: 764000, reward: 18.700000, loss: 0.000911, epsilon: 0.010000, episode:  385\n",
      "frames: 765000, reward: 18.700000, loss: 0.000327, epsilon: 0.010000, episode:  386\n",
      "frames: 766000, reward: 18.700000, loss: 0.000145, epsilon: 0.010000, episode:  386\n",
      "frames: 767000, reward: 18.600000, loss: 0.000124, epsilon: 0.010000, episode:  387\n",
      "frames: 768000, reward: 18.600000, loss: 0.000170, epsilon: 0.010000, episode:  387\n",
      "frames: 769000, reward: 18.500000, loss: 0.000464, epsilon: 0.010000, episode:  388\n",
      "frames: 770000, reward: 18.500000, loss: 0.000550, epsilon: 0.010000, episode:  388\n",
      "frames: 771000, reward: 18.500000, loss: 0.000182, epsilon: 0.010000, episode:  389\n",
      "frames: 772000, reward: 18.500000, loss: 0.000166, epsilon: 0.010000, episode:  389\n",
      "frames: 773000, reward: 18.400000, loss: 0.000232, epsilon: 0.010000, episode:  390\n",
      "frames: 774000, reward: 18.400000, loss: 0.000101, epsilon: 0.010000, episode:  390\n",
      "frames: 775000, reward: 18.400000, loss: 0.000185, epsilon: 0.010000, episode:  391\n",
      "frames: 776000, reward: 18.400000, loss: 0.000156, epsilon: 0.010000, episode:  391\n",
      "frames: 777000, reward: 18.400000, loss: 0.000188, epsilon: 0.010000, episode:  392\n",
      "frames: 778000, reward: 18.400000, loss: 0.000135, epsilon: 0.010000, episode:  392\n",
      "frames: 779000, reward: 18.600000, loss: 0.000145, epsilon: 0.010000, episode:  393\n",
      "frames: 780000, reward: 18.900000, loss: 0.000170, epsilon: 0.010000, episode:  394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 781000, reward: 18.900000, loss: 0.000251, epsilon: 0.010000, episode:  394\n",
      "frames: 782000, reward: 18.700000, loss: 0.000262, epsilon: 0.010000, episode:  395\n",
      "frames: 783000, reward: 18.700000, loss: 0.000154, epsilon: 0.010000, episode:  395\n",
      "frames: 784000, reward: 18.700000, loss: 0.001082, epsilon: 0.010000, episode:  395\n",
      "frames: 785000, reward: 17.700000, loss: 0.002373, epsilon: 0.010000, episode:  396\n",
      "frames: 786000, reward: 17.700000, loss: 0.000350, epsilon: 0.010000, episode:  396\n",
      "frames: 787000, reward: 17.800000, loss: 0.000232, epsilon: 0.010000, episode:  397\n",
      "frames: 788000, reward: 17.800000, loss: 0.001815, epsilon: 0.010000, episode:  397\n",
      "frames: 789000, reward: 17.700000, loss: 0.000263, epsilon: 0.010000, episode:  398\n",
      "frames: 790000, reward: 17.700000, loss: 0.001273, epsilon: 0.010000, episode:  398\n",
      "frames: 791000, reward: 17.400000, loss: 0.000177, epsilon: 0.010000, episode:  399\n",
      "frames: 792000, reward: 17.400000, loss: 0.000716, epsilon: 0.010000, episode:  399\n",
      "frames: 793000, reward: 17.800000, loss: 0.000393, epsilon: 0.010000, episode:  400\n",
      "frames: 794000, reward: 17.800000, loss: 0.000255, epsilon: 0.010000, episode:  400\n",
      "frames: 795000, reward: 18.000000, loss: 0.000221, epsilon: 0.010000, episode:  401\n",
      "frames: 796000, reward: 18.000000, loss: 0.000113, epsilon: 0.010000, episode:  401\n",
      "frames: 797000, reward: 18.400000, loss: 0.000112, epsilon: 0.010000, episode:  402\n",
      "frames: 798000, reward: 18.100000, loss: 0.000192, epsilon: 0.010000, episode:  403\n",
      "frames: 799000, reward: 18.100000, loss: 0.000130, epsilon: 0.010000, episode:  403\n",
      "frames: 800000, reward: 18.100000, loss: 0.001428, epsilon: 0.010000, episode:  404\n",
      "frames: 801000, reward: 18.100000, loss: 0.000183, epsilon: 0.010000, episode:  404\n",
      "frames: 802000, reward: 17.800000, loss: 0.000348, epsilon: 0.010000, episode:  405\n",
      "frames: 803000, reward: 17.800000, loss: 0.001259, epsilon: 0.010000, episode:  405\n",
      "frames: 804000, reward: 18.500000, loss: 0.000631, epsilon: 0.010000, episode:  406\n",
      "frames: 805000, reward: 18.500000, loss: 0.012286, epsilon: 0.010000, episode:  406\n",
      "frames: 806000, reward: 18.500000, loss: 0.001010, epsilon: 0.010000, episode:  407\n",
      "frames: 807000, reward: 18.500000, loss: 0.000205, epsilon: 0.010000, episode:  407\n",
      "frames: 808000, reward: 18.800000, loss: 0.000187, epsilon: 0.010000, episode:  408\n",
      "frames: 809000, reward: 18.800000, loss: 0.000146, epsilon: 0.010000, episode:  408\n",
      "frames: 810000, reward: 19.300000, loss: 0.000221, epsilon: 0.010000, episode:  409\n",
      "frames: 811000, reward: 19.400000, loss: 0.000176, epsilon: 0.010000, episode:  410\n",
      "frames: 812000, reward: 19.400000, loss: 0.000085, epsilon: 0.010000, episode:  410\n",
      "frames: 813000, reward: 19.400000, loss: 0.000121, epsilon: 0.010000, episode:  411\n",
      "frames: 814000, reward: 19.400000, loss: 0.000085, epsilon: 0.010000, episode:  411\n",
      "frames: 815000, reward: 19.500000, loss: 0.000066, epsilon: 0.010000, episode:  412\n",
      "frames: 816000, reward: 19.700000, loss: 0.000197, epsilon: 0.010000, episode:  413\n",
      "frames: 817000, reward: 19.700000, loss: 0.001343, epsilon: 0.010000, episode:  413\n",
      "frames: 818000, reward: 19.600000, loss: 0.000209, epsilon: 0.010000, episode:  414\n",
      "frames: 819000, reward: 19.600000, loss: 0.000074, epsilon: 0.010000, episode:  414\n",
      "frames: 820000, reward: 19.900000, loss: 0.000140, epsilon: 0.010000, episode:  415\n",
      "frames: 821000, reward: 19.900000, loss: 0.000104, epsilon: 0.010000, episode:  415\n",
      "frames: 822000, reward: 20.200000, loss: 0.000234, epsilon: 0.010000, episode:  416\n",
      "frames: 823000, reward: 20.200000, loss: 0.001880, epsilon: 0.010000, episode:  416\n",
      "frames: 824000, reward: 20.100000, loss: 0.000221, epsilon: 0.010000, episode:  417\n",
      "frames: 825000, reward: 20.100000, loss: 0.000344, epsilon: 0.010000, episode:  417\n",
      "frames: 826000, reward: 19.900000, loss: 0.000118, epsilon: 0.010000, episode:  418\n",
      "frames: 827000, reward: 19.900000, loss: 0.000313, epsilon: 0.010000, episode:  418\n",
      "frames: 828000, reward: 19.900000, loss: 0.000076, epsilon: 0.010000, episode:  419\n",
      "frames: 829000, reward: 19.900000, loss: 0.000204, epsilon: 0.010000, episode:  420\n",
      "frames: 830000, reward: 19.900000, loss: 0.000096, epsilon: 0.010000, episode:  420\n",
      "frames: 831000, reward: 19.900000, loss: 0.000260, epsilon: 0.010000, episode:  421\n",
      "frames: 832000, reward: 19.900000, loss: 0.000104, epsilon: 0.010000, episode:  421\n",
      "frames: 833000, reward: 19.800000, loss: 0.000411, epsilon: 0.010000, episode:  422\n",
      "frames: 834000, reward: 19.700000, loss: 0.000490, epsilon: 0.010000, episode:  423\n",
      "frames: 835000, reward: 19.700000, loss: 0.000319, epsilon: 0.010000, episode:  423\n",
      "frames: 836000, reward: 19.800000, loss: 0.000142, epsilon: 0.010000, episode:  424\n",
      "frames: 837000, reward: 19.800000, loss: 0.000579, epsilon: 0.010000, episode:  424\n",
      "frames: 838000, reward: 20.100000, loss: 0.000215, epsilon: 0.010000, episode:  425\n",
      "frames: 839000, reward: 20.100000, loss: 0.000044, epsilon: 0.010000, episode:  425\n",
      "frames: 840000, reward: 20.100000, loss: 0.000037, epsilon: 0.010000, episode:  426\n",
      "frames: 841000, reward: 20.100000, loss: 0.000035, epsilon: 0.010000, episode:  426\n",
      "frames: 842000, reward: 20.000000, loss: 0.000360, epsilon: 0.010000, episode:  427\n",
      "frames: 843000, reward: 20.200000, loss: 0.000173, epsilon: 0.010000, episode:  428\n",
      "frames: 844000, reward: 20.200000, loss: 0.001613, epsilon: 0.010000, episode:  428\n",
      "frames: 845000, reward: 19.800000, loss: 0.000316, epsilon: 0.010000, episode:  429\n",
      "frames: 846000, reward: 19.800000, loss: 0.000249, epsilon: 0.010000, episode:  429\n",
      "frames: 847000, reward: 19.500000, loss: 0.000156, epsilon: 0.010000, episode:  430\n",
      "frames: 848000, reward: 19.500000, loss: 0.000134, epsilon: 0.010000, episode:  430\n",
      "frames: 849000, reward: 19.500000, loss: 0.000126, epsilon: 0.010000, episode:  431\n",
      "frames: 850000, reward: 19.500000, loss: 0.000238, epsilon: 0.010000, episode:  431\n",
      "frames: 851000, reward: 18.500000, loss: 0.000154, epsilon: 0.010000, episode:  432\n",
      "frames: 852000, reward: 18.500000, loss: 0.000179, epsilon: 0.010000, episode:  432\n",
      "frames: 853000, reward: 18.700000, loss: 0.000097, epsilon: 0.010000, episode:  433\n",
      "frames: 854000, reward: 18.600000, loss: 0.012144, epsilon: 0.010000, episode:  434\n",
      "frames: 855000, reward: 18.600000, loss: 0.000236, epsilon: 0.010000, episode:  434\n",
      "frames: 856000, reward: 18.700000, loss: 0.000239, epsilon: 0.010000, episode:  435\n",
      "frames: 857000, reward: 18.700000, loss: 0.000212, epsilon: 0.010000, episode:  435\n",
      "frames: 858000, reward: 18.700000, loss: 0.000203, epsilon: 0.010000, episode:  435\n",
      "frames: 859000, reward: 17.700000, loss: 0.000199, epsilon: 0.010000, episode:  436\n",
      "frames: 860000, reward: 17.700000, loss: 0.000094, epsilon: 0.010000, episode:  436\n",
      "frames: 861000, reward: 17.800000, loss: 0.000122, epsilon: 0.010000, episode:  437\n",
      "frames: 862000, reward: 17.800000, loss: 0.000226, epsilon: 0.010000, episode:  438\n",
      "frames: 863000, reward: 17.800000, loss: 0.000098, epsilon: 0.010000, episode:  438\n",
      "frames: 864000, reward: 18.000000, loss: 0.000269, epsilon: 0.010000, episode:  439\n",
      "frames: 865000, reward: 18.000000, loss: 0.000299, epsilon: 0.010000, episode:  439\n",
      "frames: 866000, reward: 18.200000, loss: 0.000213, epsilon: 0.010000, episode:  440\n",
      "frames: 867000, reward: 18.200000, loss: 0.000081, epsilon: 0.010000, episode:  440\n",
      "frames: 868000, reward: 18.200000, loss: 0.000069, epsilon: 0.010000, episode:  441\n",
      "frames: 869000, reward: 18.200000, loss: 0.000138, epsilon: 0.010000, episode:  441\n",
      "frames: 870000, reward: 19.300000, loss: 0.000147, epsilon: 0.010000, episode:  442\n",
      "frames: 871000, reward: 19.000000, loss: 0.000139, epsilon: 0.010000, episode:  443\n",
      "frames: 872000, reward: 19.000000, loss: 0.000238, epsilon: 0.010000, episode:  443\n",
      "frames: 873000, reward: 19.000000, loss: 0.000065, epsilon: 0.010000, episode:  443\n",
      "frames: 874000, reward: 18.300000, loss: 0.000157, epsilon: 0.010000, episode:  444\n",
      "frames: 875000, reward: 18.300000, loss: 0.000107, epsilon: 0.010000, episode:  444\n",
      "frames: 876000, reward: 17.700000, loss: 0.000194, epsilon: 0.010000, episode:  445\n",
      "frames: 877000, reward: 18.700000, loss: 0.001555, epsilon: 0.010000, episode:  446\n",
      "frames: 878000, reward: 18.700000, loss: 0.000234, epsilon: 0.010000, episode:  446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 879000, reward: 18.700000, loss: 0.000270, epsilon: 0.010000, episode:  446\n",
      "frames: 880000, reward: 18.100000, loss: 0.000122, epsilon: 0.010000, episode:  447\n",
      "frames: 881000, reward: 18.100000, loss: 0.000127, epsilon: 0.010000, episode:  447\n",
      "frames: 882000, reward: 17.200000, loss: 0.000233, epsilon: 0.010000, episode:  448\n",
      "frames: 883000, reward: 17.200000, loss: 0.000297, epsilon: 0.010000, episode:  448\n",
      "frames: 884000, reward: 17.300000, loss: 0.000258, epsilon: 0.010000, episode:  449\n",
      "frames: 885000, reward: 17.400000, loss: 0.000209, epsilon: 0.010000, episode:  450\n",
      "frames: 886000, reward: 17.400000, loss: 0.000743, epsilon: 0.010000, episode:  450\n",
      "frames: 887000, reward: 17.400000, loss: 0.000424, epsilon: 0.010000, episode:  450\n",
      "frames: 888000, reward: 16.500000, loss: 0.000973, epsilon: 0.010000, episode:  451\n",
      "frames: 889000, reward: 16.500000, loss: 0.000125, epsilon: 0.010000, episode:  451\n",
      "frames: 890000, reward: 16.400000, loss: 0.000252, epsilon: 0.010000, episode:  452\n",
      "frames: 891000, reward: 16.400000, loss: 0.000724, epsilon: 0.010000, episode:  452\n",
      "frames: 892000, reward: 16.600000, loss: 0.000156, epsilon: 0.010000, episode:  453\n",
      "frames: 893000, reward: 17.300000, loss: 0.000232, epsilon: 0.010000, episode:  454\n",
      "frames: 894000, reward: 17.300000, loss: 0.000164, epsilon: 0.010000, episode:  454\n",
      "frames: 895000, reward: 17.800000, loss: 0.000132, epsilon: 0.010000, episode:  455\n",
      "frames: 896000, reward: 17.800000, loss: 0.000072, epsilon: 0.010000, episode:  455\n",
      "frames: 897000, reward: 17.700000, loss: 0.000072, epsilon: 0.010000, episode:  456\n",
      "frames: 898000, reward: 17.700000, loss: 0.000115, epsilon: 0.010000, episode:  456\n",
      "frames: 899000, reward: 18.300000, loss: 0.000075, epsilon: 0.010000, episode:  457\n",
      "frames: 900000, reward: 18.300000, loss: 0.000186, epsilon: 0.010000, episode:  457\n",
      "frames: 901000, reward: 18.900000, loss: 0.000228, epsilon: 0.010000, episode:  458\n",
      "frames: 902000, reward: 19.000000, loss: 0.000141, epsilon: 0.010000, episode:  459\n",
      "frames: 903000, reward: 19.000000, loss: 0.000174, epsilon: 0.010000, episode:  459\n",
      "frames: 904000, reward: 18.700000, loss: 0.000280, epsilon: 0.010000, episode:  460\n",
      "frames: 905000, reward: 18.700000, loss: 0.000059, epsilon: 0.010000, episode:  460\n",
      "frames: 906000, reward: 19.600000, loss: 0.000123, epsilon: 0.010000, episode:  461\n",
      "frames: 907000, reward: 19.700000, loss: 0.000149, epsilon: 0.010000, episode:  462\n",
      "frames: 908000, reward: 19.700000, loss: 0.000135, epsilon: 0.010000, episode:  462\n",
      "frames: 909000, reward: 19.800000, loss: 0.000134, epsilon: 0.010000, episode:  463\n",
      "frames: 910000, reward: 19.800000, loss: 0.000060, epsilon: 0.010000, episode:  463\n",
      "frames: 911000, reward: 19.600000, loss: 0.000173, epsilon: 0.010000, episode:  464\n",
      "frames: 912000, reward: 19.600000, loss: 0.000142, epsilon: 0.010000, episode:  464\n",
      "frames: 913000, reward: 19.700000, loss: 0.000037, epsilon: 0.010000, episode:  465\n",
      "frames: 914000, reward: 19.800000, loss: 0.000188, epsilon: 0.010000, episode:  466\n",
      "frames: 915000, reward: 19.800000, loss: 0.001393, epsilon: 0.010000, episode:  466\n",
      "frames: 916000, reward: 19.800000, loss: 0.000132, epsilon: 0.010000, episode:  467\n",
      "frames: 917000, reward: 19.800000, loss: 0.000124, epsilon: 0.010000, episode:  467\n",
      "frames: 918000, reward: 20.000000, loss: 0.000291, epsilon: 0.010000, episode:  468\n",
      "frames: 919000, reward: 20.000000, loss: 0.000239, epsilon: 0.010000, episode:  468\n",
      "frames: 920000, reward: 20.000000, loss: 0.000299, epsilon: 0.010000, episode:  468\n",
      "frames: 921000, reward: 18.300000, loss: 0.000174, epsilon: 0.010000, episode:  469\n",
      "frames: 922000, reward: 18.300000, loss: 0.000121, epsilon: 0.010000, episode:  469\n",
      "frames: 923000, reward: 18.200000, loss: 0.000325, epsilon: 0.010000, episode:  470\n",
      "frames: 924000, reward: 18.200000, loss: 0.000368, epsilon: 0.010000, episode:  470\n",
      "frames: 925000, reward: 18.000000, loss: 0.000180, epsilon: 0.010000, episode:  471\n",
      "frames: 926000, reward: 17.800000, loss: 0.000188, epsilon: 0.010000, episode:  472\n",
      "frames: 927000, reward: 17.800000, loss: 0.000119, epsilon: 0.010000, episode:  472\n",
      "frames: 928000, reward: 17.500000, loss: 0.000191, epsilon: 0.010000, episode:  473\n",
      "frames: 929000, reward: 17.500000, loss: 0.000125, epsilon: 0.010000, episode:  473\n",
      "frames: 930000, reward: 17.500000, loss: 0.000343, epsilon: 0.010000, episode:  474\n",
      "frames: 931000, reward: 17.500000, loss: 0.000479, epsilon: 0.010000, episode:  474\n",
      "frames: 932000, reward: 17.300000, loss: 0.000285, epsilon: 0.010000, episode:  475\n",
      "frames: 933000, reward: 17.300000, loss: 0.000133, epsilon: 0.010000, episode:  475\n",
      "frames: 934000, reward: 17.300000, loss: 0.000126, epsilon: 0.010000, episode:  476\n",
      "frames: 935000, reward: 17.300000, loss: 0.000107, epsilon: 0.010000, episode:  476\n",
      "frames: 936000, reward: 17.300000, loss: 0.000104, epsilon: 0.010000, episode:  477\n",
      "frames: 937000, reward: 17.300000, loss: 0.000276, epsilon: 0.010000, episode:  478\n",
      "frames: 938000, reward: 17.300000, loss: 0.000152, epsilon: 0.010000, episode:  478\n",
      "frames: 939000, reward: 19.000000, loss: 0.000133, epsilon: 0.010000, episode:  479\n",
      "frames: 940000, reward: 19.000000, loss: 0.000107, epsilon: 0.010000, episode:  479\n",
      "frames: 941000, reward: 19.300000, loss: 0.000123, epsilon: 0.010000, episode:  480\n",
      "frames: 942000, reward: 19.300000, loss: 0.000128, epsilon: 0.010000, episode:  480\n",
      "frames: 943000, reward: 19.400000, loss: 0.000164, epsilon: 0.010000, episode:  481\n",
      "frames: 944000, reward: 19.400000, loss: 0.000069, epsilon: 0.010000, episode:  481\n",
      "frames: 945000, reward: 19.100000, loss: 0.000095, epsilon: 0.010000, episode:  482\n",
      "frames: 946000, reward: 19.200000, loss: 0.000157, epsilon: 0.010000, episode:  483\n",
      "frames: 947000, reward: 19.200000, loss: 0.000109, epsilon: 0.010000, episode:  483\n",
      "frames: 948000, reward: 19.400000, loss: 0.000106, epsilon: 0.010000, episode:  484\n",
      "frames: 949000, reward: 19.400000, loss: 0.000140, epsilon: 0.010000, episode:  484\n",
      "frames: 950000, reward: 19.400000, loss: 0.000170, epsilon: 0.010000, episode:  485\n",
      "frames: 951000, reward: 19.400000, loss: 0.000276, epsilon: 0.010000, episode:  485\n",
      "frames: 952000, reward: 19.500000, loss: 0.000096, epsilon: 0.010000, episode:  486\n",
      "frames: 953000, reward: 19.700000, loss: 0.000107, epsilon: 0.010000, episode:  487\n",
      "frames: 954000, reward: 19.700000, loss: 0.002556, epsilon: 0.010000, episode:  487\n",
      "frames: 955000, reward: 19.300000, loss: 0.000112, epsilon: 0.010000, episode:  488\n",
      "frames: 956000, reward: 19.300000, loss: 0.000145, epsilon: 0.010000, episode:  488\n",
      "frames: 957000, reward: 19.200000, loss: 0.000192, epsilon: 0.010000, episode:  489\n",
      "frames: 958000, reward: 19.200000, loss: 0.000287, epsilon: 0.010000, episode:  489\n",
      "frames: 959000, reward: 19.300000, loss: 0.000067, epsilon: 0.010000, episode:  490\n",
      "frames: 960000, reward: 19.300000, loss: 0.000233, epsilon: 0.010000, episode:  491\n",
      "frames: 961000, reward: 19.300000, loss: 0.000079, epsilon: 0.010000, episode:  491\n",
      "frames: 962000, reward: 19.600000, loss: 0.000166, epsilon: 0.010000, episode:  492\n",
      "frames: 963000, reward: 19.600000, loss: 0.000135, epsilon: 0.010000, episode:  492\n",
      "frames: 964000, reward: 19.800000, loss: 0.000109, epsilon: 0.010000, episode:  493\n",
      "frames: 965000, reward: 19.800000, loss: 0.000217, epsilon: 0.010000, episode:  493\n",
      "frames: 966000, reward: 19.700000, loss: 0.000434, epsilon: 0.010000, episode:  494\n",
      "frames: 967000, reward: 19.700000, loss: 0.000104, epsilon: 0.010000, episode:  494\n",
      "frames: 968000, reward: 19.400000, loss: 0.000318, epsilon: 0.010000, episode:  495\n",
      "frames: 969000, reward: 19.400000, loss: 0.000120, epsilon: 0.010000, episode:  495\n",
      "frames: 970000, reward: 19.100000, loss: 0.000414, epsilon: 0.010000, episode:  496\n",
      "frames: 971000, reward: 19.100000, loss: 0.000060, epsilon: 0.010000, episode:  496\n",
      "frames: 972000, reward: 18.900000, loss: 0.000163, epsilon: 0.010000, episode:  497\n",
      "frames: 973000, reward: 19.300000, loss: 0.000180, epsilon: 0.010000, episode:  498\n",
      "frames: 974000, reward: 19.300000, loss: 0.000120, epsilon: 0.010000, episode:  498\n",
      "frames: 975000, reward: 19.100000, loss: 0.000109, epsilon: 0.010000, episode:  499\n",
      "frames: 976000, reward: 19.100000, loss: 0.000147, epsilon: 0.010000, episode:  499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 977000, reward: 19.100000, loss: 0.000229, epsilon: 0.010000, episode:  499\n",
      "frames: 978000, reward: 18.400000, loss: 0.000189, epsilon: 0.010000, episode:  500\n",
      "frames: 979000, reward: 18.500000, loss: 0.000407, epsilon: 0.010000, episode:  501\n",
      "frames: 980000, reward: 18.500000, loss: 0.000141, epsilon: 0.010000, episode:  501\n",
      "frames: 981000, reward: 18.500000, loss: 0.000267, epsilon: 0.010000, episode:  502\n",
      "frames: 982000, reward: 18.500000, loss: 0.001158, epsilon: 0.010000, episode:  502\n",
      "frames: 983000, reward: 18.000000, loss: 0.000220, epsilon: 0.010000, episode:  503\n",
      "frames: 984000, reward: 18.000000, loss: 0.000354, epsilon: 0.010000, episode:  503\n",
      "frames: 985000, reward: 18.100000, loss: 0.000124, epsilon: 0.010000, episode:  504\n",
      "frames: 986000, reward: 18.100000, loss: 0.000708, epsilon: 0.010000, episode:  504\n",
      "frames: 987000, reward: 18.100000, loss: 0.000306, epsilon: 0.010000, episode:  504\n",
      "frames: 988000, reward: 18.000000, loss: 0.000591, epsilon: 0.010000, episode:  505\n",
      "frames: 989000, reward: 18.000000, loss: 0.000102, epsilon: 0.010000, episode:  505\n",
      "frames: 990000, reward: 18.000000, loss: 0.001447, epsilon: 0.010000, episode:  506\n",
      "frames: 991000, reward: 18.000000, loss: 0.000217, epsilon: 0.010000, episode:  506\n",
      "frames: 992000, reward: 17.600000, loss: 0.000109, epsilon: 0.010000, episode:  507\n",
      "frames: 993000, reward: 17.600000, loss: 0.000119, epsilon: 0.010000, episode:  507\n",
      "frames: 994000, reward: 17.600000, loss: 0.000124, epsilon: 0.010000, episode:  508\n",
      "frames: 995000, reward: 17.700000, loss: 0.000396, epsilon: 0.010000, episode:  509\n",
      "frames: 996000, reward: 17.700000, loss: 0.000104, epsilon: 0.010000, episode:  509\n",
      "frames: 997000, reward: 18.300000, loss: 0.000263, epsilon: 0.010000, episode:  510\n",
      "frames: 998000, reward: 18.300000, loss: 0.000236, epsilon: 0.010000, episode:  510\n",
      "frames: 999000, reward: 18.200000, loss: 0.000162, epsilon: 0.010000, episode:  511\n",
      "frames: 1000000, reward: 18.200000, loss: 0.000138, epsilon: 0.010000, episode:  511\n",
      "frames: 1001000, reward: 18.400000, loss: 0.000140, epsilon: 0.010000, episode:  512\n",
      "frames: 1002000, reward: 18.400000, loss: 0.000977, epsilon: 0.010000, episode:  512\n",
      "frames: 1003000, reward: 18.400000, loss: 0.000324, epsilon: 0.010000, episode:  512\n",
      "frames: 1004000, reward: 18.100000, loss: 0.000184, epsilon: 0.010000, episode:  513\n",
      "frames: 1005000, reward: 18.100000, loss: 0.000356, epsilon: 0.010000, episode:  513\n",
      "frames: 1006000, reward: 18.100000, loss: 0.000376, epsilon: 0.010000, episode:  514\n",
      "frames: 1007000, reward: 18.100000, loss: 0.000184, epsilon: 0.010000, episode:  514\n",
      "frames: 1008000, reward: 18.500000, loss: 0.001524, epsilon: 0.010000, episode:  515\n",
      "frames: 1009000, reward: 18.800000, loss: 0.000162, epsilon: 0.010000, episode:  516\n",
      "frames: 1010000, reward: 18.800000, loss: 0.000188, epsilon: 0.010000, episode:  516\n",
      "frames: 1011000, reward: 19.400000, loss: 0.000154, epsilon: 0.010000, episode:  517\n",
      "frames: 1012000, reward: 19.400000, loss: 0.000244, epsilon: 0.010000, episode:  517\n",
      "frames: 1013000, reward: 19.200000, loss: 0.000102, epsilon: 0.010000, episode:  518\n",
      "frames: 1014000, reward: 19.200000, loss: 0.000099, epsilon: 0.010000, episode:  518\n",
      "frames: 1015000, reward: 19.400000, loss: 0.000107, epsilon: 0.010000, episode:  519\n",
      "frames: 1016000, reward: 19.400000, loss: 0.000177, epsilon: 0.010000, episode:  520\n",
      "frames: 1017000, reward: 19.400000, loss: 0.000071, epsilon: 0.010000, episode:  520\n",
      "frames: 1018000, reward: 19.500000, loss: 0.000147, epsilon: 0.010000, episode:  521\n",
      "frames: 1019000, reward: 19.500000, loss: 0.000068, epsilon: 0.010000, episode:  521\n",
      "frames: 1020000, reward: 19.100000, loss: 0.000138, epsilon: 0.010000, episode:  522\n",
      "frames: 1021000, reward: 19.100000, loss: 0.000276, epsilon: 0.010000, episode:  522\n",
      "frames: 1022000, reward: 19.800000, loss: 0.000735, epsilon: 0.010000, episode:  523\n",
      "frames: 1023000, reward: 19.800000, loss: 0.000084, epsilon: 0.010000, episode:  523\n",
      "frames: 1024000, reward: 19.400000, loss: 0.000163, epsilon: 0.010000, episode:  524\n",
      "frames: 1025000, reward: 19.400000, loss: 0.000089, epsilon: 0.010000, episode:  524\n",
      "frames: 1026000, reward: 19.500000, loss: 0.000081, epsilon: 0.010000, episode:  525\n",
      "frames: 1027000, reward: 19.500000, loss: 0.001245, epsilon: 0.010000, episode:  525\n",
      "frames: 1028000, reward: 19.200000, loss: 0.000241, epsilon: 0.010000, episode:  526\n",
      "frames: 1029000, reward: 19.000000, loss: 0.000542, epsilon: 0.010000, episode:  527\n",
      "frames: 1030000, reward: 19.000000, loss: 0.001063, epsilon: 0.010000, episode:  527\n",
      "frames: 1031000, reward: 18.800000, loss: 0.000137, epsilon: 0.010000, episode:  528\n",
      "frames: 1032000, reward: 18.800000, loss: 0.000130, epsilon: 0.010000, episode:  528\n",
      "frames: 1033000, reward: 18.600000, loss: 0.000133, epsilon: 0.010000, episode:  529\n",
      "frames: 1034000, reward: 18.600000, loss: 0.000115, epsilon: 0.010000, episode:  529\n",
      "frames: 1035000, reward: 18.600000, loss: 0.000123, epsilon: 0.010000, episode:  530\n",
      "frames: 1036000, reward: 18.600000, loss: 0.000151, epsilon: 0.010000, episode:  530\n",
      "frames: 1037000, reward: 18.300000, loss: 0.000214, epsilon: 0.010000, episode:  531\n",
      "frames: 1038000, reward: 18.600000, loss: 0.000290, epsilon: 0.010000, episode:  532\n",
      "frames: 1039000, reward: 18.600000, loss: 0.000126, epsilon: 0.010000, episode:  532\n",
      "frames: 1040000, reward: 18.600000, loss: 0.000166, epsilon: 0.010000, episode:  532\n",
      "frames: 1041000, reward: 18.300000, loss: 0.000607, epsilon: 0.010000, episode:  533\n",
      "frames: 1042000, reward: 18.700000, loss: 0.000328, epsilon: 0.010000, episode:  534\n",
      "frames: 1043000, reward: 18.700000, loss: 0.000094, epsilon: 0.010000, episode:  534\n",
      "frames: 1044000, reward: 18.700000, loss: 0.000117, epsilon: 0.010000, episode:  535\n",
      "frames: 1045000, reward: 18.700000, loss: 0.000140, epsilon: 0.010000, episode:  535\n",
      "frames: 1046000, reward: 18.900000, loss: 0.000190, epsilon: 0.010000, episode:  536\n",
      "frames: 1047000, reward: 18.900000, loss: 0.003372, epsilon: 0.010000, episode:  536\n",
      "frames: 1048000, reward: 18.700000, loss: 0.000252, epsilon: 0.010000, episode:  537\n",
      "frames: 1049000, reward: 18.700000, loss: 0.000198, epsilon: 0.010000, episode:  537\n",
      "frames: 1050000, reward: 18.600000, loss: 0.000512, epsilon: 0.010000, episode:  538\n",
      "frames: 1051000, reward: 18.600000, loss: 0.000109, epsilon: 0.010000, episode:  538\n",
      "frames: 1052000, reward: 18.500000, loss: 0.000108, epsilon: 0.010000, episode:  539\n",
      "frames: 1053000, reward: 18.500000, loss: 0.001086, epsilon: 0.010000, episode:  539\n",
      "frames: 1054000, reward: 18.500000, loss: 0.000237, epsilon: 0.010000, episode:  539\n",
      "frames: 1055000, reward: 17.900000, loss: 0.000237, epsilon: 0.010000, episode:  540\n",
      "frames: 1056000, reward: 17.900000, loss: 0.000171, epsilon: 0.010000, episode:  540\n",
      "frames: 1057000, reward: 17.500000, loss: 0.000237, epsilon: 0.010000, episode:  541\n",
      "frames: 1058000, reward: 17.500000, loss: 0.000254, epsilon: 0.010000, episode:  541\n",
      "frames: 1059000, reward: 17.200000, loss: 0.000482, epsilon: 0.010000, episode:  542\n",
      "frames: 1060000, reward: 17.200000, loss: 0.001419, epsilon: 0.010000, episode:  542\n",
      "frames: 1061000, reward: 17.200000, loss: 0.000218, epsilon: 0.010000, episode:  543\n",
      "frames: 1062000, reward: 17.200000, loss: 0.000528, epsilon: 0.010000, episode:  543\n",
      "frames: 1063000, reward: 17.200000, loss: 0.000432, epsilon: 0.010000, episode:  543\n",
      "frames: 1064000, reward: 16.900000, loss: 0.000261, epsilon: 0.010000, episode:  544\n",
      "frames: 1065000, reward: 16.900000, loss: 0.000144, epsilon: 0.010000, episode:  544\n",
      "frames: 1066000, reward: 16.800000, loss: 0.000916, epsilon: 0.010000, episode:  545\n",
      "frames: 1067000, reward: 16.800000, loss: 0.000232, epsilon: 0.010000, episode:  545\n",
      "frames: 1068000, reward: 16.500000, loss: 0.000591, epsilon: 0.010000, episode:  546\n",
      "frames: 1069000, reward: 16.900000, loss: 0.000571, epsilon: 0.010000, episode:  547\n",
      "frames: 1070000, reward: 16.900000, loss: 0.000268, epsilon: 0.010000, episode:  547\n",
      "frames: 1071000, reward: 17.300000, loss: 0.000210, epsilon: 0.010000, episode:  548\n",
      "frames: 1072000, reward: 17.300000, loss: 0.000323, epsilon: 0.010000, episode:  548\n",
      "frames: 1073000, reward: 17.500000, loss: 0.000165, epsilon: 0.010000, episode:  549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 1074000, reward: 18.200000, loss: 0.000401, epsilon: 0.010000, episode:  550\n",
      "frames: 1075000, reward: 18.200000, loss: 0.000600, epsilon: 0.010000, episode:  550\n",
      "frames: 1076000, reward: 18.700000, loss: 0.000148, epsilon: 0.010000, episode:  551\n",
      "frames: 1077000, reward: 18.700000, loss: 0.000131, epsilon: 0.010000, episode:  551\n",
      "frames: 1078000, reward: 19.000000, loss: 0.000374, epsilon: 0.010000, episode:  552\n",
      "frames: 1079000, reward: 19.000000, loss: 0.000097, epsilon: 0.010000, episode:  552\n",
      "frames: 1080000, reward: 19.000000, loss: 0.000377, epsilon: 0.010000, episode:  553\n",
      "frames: 1081000, reward: 19.000000, loss: 0.000237, epsilon: 0.010000, episode:  553\n",
      "frames: 1082000, reward: 19.200000, loss: 0.000165, epsilon: 0.010000, episode:  554\n",
      "frames: 1083000, reward: 19.200000, loss: 0.000172, epsilon: 0.010000, episode:  554\n",
      "frames: 1084000, reward: 19.400000, loss: 0.000136, epsilon: 0.010000, episode:  555\n",
      "frames: 1085000, reward: 19.700000, loss: 0.000228, epsilon: 0.010000, episode:  556\n",
      "frames: 1086000, reward: 19.700000, loss: 0.000069, epsilon: 0.010000, episode:  556\n",
      "frames: 1087000, reward: 19.700000, loss: 0.000129, epsilon: 0.010000, episode:  557\n",
      "frames: 1088000, reward: 19.700000, loss: 0.000093, epsilon: 0.010000, episode:  557\n",
      "frames: 1089000, reward: 19.900000, loss: 0.000216, epsilon: 0.010000, episode:  558\n",
      "frames: 1090000, reward: 19.900000, loss: 1.012750, epsilon: 0.010000, episode:  558\n",
      "frames: 1091000, reward: 19.900000, loss: 0.000097, epsilon: 0.010000, episode:  559\n",
      "frames: 1092000, reward: 19.900000, loss: 0.000115, epsilon: 0.010000, episode:  560\n",
      "frames: 1093000, reward: 19.900000, loss: 0.000164, epsilon: 0.010000, episode:  560\n",
      "frames: 1094000, reward: 20.000000, loss: 0.000068, epsilon: 0.010000, episode:  561\n",
      "frames: 1095000, reward: 20.000000, loss: 0.000057, epsilon: 0.010000, episode:  561\n",
      "frames: 1096000, reward: 19.900000, loss: 0.000040, epsilon: 0.010000, episode:  562\n",
      "frames: 1097000, reward: 19.900000, loss: 0.000225, epsilon: 0.010000, episode:  562\n",
      "frames: 1098000, reward: 19.900000, loss: 0.000212, epsilon: 0.010000, episode:  563\n",
      "frames: 1099000, reward: 19.900000, loss: 0.000546, epsilon: 0.010000, episode:  563\n",
      "frames: 1100000, reward: 19.700000, loss: 0.000102, epsilon: 0.010000, episode:  564\n",
      "frames: 1101000, reward: 19.700000, loss: 0.000376, epsilon: 0.010000, episode:  565\n",
      "frames: 1102000, reward: 19.700000, loss: 0.000203, epsilon: 0.010000, episode:  565\n",
      "frames: 1103000, reward: 19.700000, loss: 0.000183, epsilon: 0.010000, episode:  566\n",
      "frames: 1104000, reward: 19.700000, loss: 0.000097, epsilon: 0.010000, episode:  566\n",
      "frames: 1105000, reward: 19.400000, loss: 0.000454, epsilon: 0.010000, episode:  567\n",
      "frames: 1106000, reward: 19.400000, loss: 0.000127, epsilon: 0.010000, episode:  567\n",
      "frames: 1107000, reward: 19.000000, loss: 0.000089, epsilon: 0.010000, episode:  568\n",
      "frames: 1108000, reward: 19.000000, loss: 0.000402, epsilon: 0.010000, episode:  568\n",
      "frames: 1109000, reward: 19.000000, loss: 0.001710, epsilon: 0.010000, episode:  569\n",
      "frames: 1110000, reward: 19.000000, loss: 0.000274, epsilon: 0.010000, episode:  569\n",
      "frames: 1111000, reward: 19.000000, loss: 0.000090, epsilon: 0.010000, episode:  570\n",
      "frames: 1112000, reward: 19.000000, loss: 0.000141, epsilon: 0.010000, episode:  570\n",
      "frames: 1113000, reward: 18.900000, loss: 0.000152, epsilon: 0.010000, episode:  571\n",
      "frames: 1114000, reward: 18.600000, loss: 0.000632, epsilon: 0.010000, episode:  572\n",
      "frames: 1115000, reward: 18.600000, loss: 0.000567, epsilon: 0.010000, episode:  572\n",
      "frames: 1116000, reward: 18.800000, loss: 0.000173, epsilon: 0.010000, episode:  573\n",
      "frames: 1117000, reward: 18.800000, loss: 0.000404, epsilon: 0.010000, episode:  573\n",
      "frames: 1118000, reward: 19.100000, loss: 0.000175, epsilon: 0.010000, episode:  574\n",
      "frames: 1119000, reward: 19.100000, loss: 0.000124, epsilon: 0.010000, episode:  574\n",
      "frames: 1120000, reward: 18.900000, loss: 0.000134, epsilon: 0.010000, episode:  575\n",
      "frames: 1121000, reward: 18.900000, loss: 0.000055, epsilon: 0.010000, episode:  575\n",
      "frames: 1122000, reward: 18.700000, loss: 0.000361, epsilon: 0.010000, episode:  576\n",
      "frames: 1123000, reward: 18.700000, loss: 0.000129, epsilon: 0.010000, episode:  576\n",
      "frames: 1124000, reward: 18.600000, loss: 0.000437, epsilon: 0.010000, episode:  577\n",
      "frames: 1125000, reward: 18.600000, loss: 0.000138, epsilon: 0.010000, episode:  577\n",
      "frames: 1126000, reward: 18.900000, loss: 0.000173, epsilon: 0.010000, episode:  578\n",
      "frames: 1127000, reward: 18.900000, loss: 0.000344, epsilon: 0.010000, episode:  578\n",
      "frames: 1128000, reward: 18.500000, loss: 0.000090, epsilon: 0.010000, episode:  579\n",
      "frames: 1129000, reward: 18.500000, loss: 0.000059, epsilon: 0.010000, episode:  579\n",
      "frames: 1130000, reward: 18.300000, loss: 0.000232, epsilon: 0.010000, episode:  580\n",
      "frames: 1131000, reward: 18.300000, loss: 0.000398, epsilon: 0.010000, episode:  580\n",
      "frames: 1132000, reward: 18.200000, loss: 0.000904, epsilon: 0.010000, episode:  581\n",
      "frames: 1133000, reward: 18.200000, loss: 0.000127, epsilon: 0.010000, episode:  581\n",
      "frames: 1134000, reward: 18.500000, loss: 0.005181, epsilon: 0.010000, episode:  582\n",
      "frames: 1135000, reward: 18.500000, loss: 0.000278, epsilon: 0.010000, episode:  582\n",
      "frames: 1136000, reward: 17.700000, loss: 0.000112, epsilon: 0.010000, episode:  583\n",
      "frames: 1137000, reward: 17.700000, loss: 0.000230, epsilon: 0.010000, episode:  583\n",
      "frames: 1138000, reward: 17.700000, loss: 0.000375, epsilon: 0.010000, episode:  584\n",
      "frames: 1139000, reward: 17.700000, loss: 0.000139, epsilon: 0.010000, episode:  584\n",
      "frames: 1140000, reward: 17.800000, loss: 0.000221, epsilon: 0.010000, episode:  585\n",
      "frames: 1141000, reward: 17.800000, loss: 0.000209, epsilon: 0.010000, episode:  585\n",
      "frames: 1142000, reward: 17.900000, loss: 0.000320, epsilon: 0.010000, episode:  586\n",
      "frames: 1143000, reward: 17.900000, loss: 0.000215, epsilon: 0.010000, episode:  586\n",
      "frames: 1144000, reward: 17.700000, loss: 0.001968, epsilon: 0.010000, episode:  587\n",
      "frames: 1145000, reward: 17.700000, loss: 0.000096, epsilon: 0.010000, episode:  587\n",
      "frames: 1146000, reward: 17.700000, loss: 0.000184, epsilon: 0.010000, episode:  588\n",
      "frames: 1147000, reward: 17.700000, loss: 0.000150, epsilon: 0.010000, episode:  588\n",
      "frames: 1148000, reward: 18.200000, loss: 0.000583, epsilon: 0.010000, episode:  589\n",
      "frames: 1149000, reward: 18.200000, loss: 0.000131, epsilon: 0.010000, episode:  589\n",
      "frames: 1150000, reward: 18.100000, loss: 0.000346, epsilon: 0.010000, episode:  590\n",
      "frames: 1151000, reward: 18.100000, loss: 0.000103, epsilon: 0.010000, episode:  590\n",
      "frames: 1152000, reward: 17.900000, loss: 0.001149, epsilon: 0.010000, episode:  591\n",
      "frames: 1153000, reward: 17.900000, loss: 0.000273, epsilon: 0.010000, episode:  591\n",
      "frames: 1154000, reward: 18.100000, loss: 0.000075, epsilon: 0.010000, episode:  592\n",
      "frames: 1155000, reward: 19.000000, loss: 0.000114, epsilon: 0.010000, episode:  593\n",
      "frames: 1156000, reward: 19.000000, loss: 0.000166, epsilon: 0.010000, episode:  593\n",
      "frames: 1157000, reward: 18.800000, loss: 0.000873, epsilon: 0.010000, episode:  594\n",
      "frames: 1158000, reward: 18.800000, loss: 0.000089, epsilon: 0.010000, episode:  594\n",
      "frames: 1159000, reward: 18.700000, loss: 0.000246, epsilon: 0.010000, episode:  595\n",
      "frames: 1160000, reward: 18.700000, loss: 0.000166, epsilon: 0.010000, episode:  595\n",
      "frames: 1161000, reward: 18.800000, loss: 0.000160, epsilon: 0.010000, episode:  596\n",
      "frames: 1162000, reward: 19.300000, loss: 0.000344, epsilon: 0.010000, episode:  597\n",
      "frames: 1163000, reward: 19.300000, loss: 0.000151, epsilon: 0.010000, episode:  597\n",
      "frames: 1164000, reward: 19.200000, loss: 0.000204, epsilon: 0.010000, episode:  598\n",
      "frames: 1165000, reward: 19.200000, loss: 0.000127, epsilon: 0.010000, episode:  598\n",
      "frames: 1166000, reward: 19.200000, loss: 0.000129, epsilon: 0.010000, episode:  599\n",
      "frames: 1167000, reward: 19.200000, loss: 0.000243, epsilon: 0.010000, episode:  599\n",
      "frames: 1168000, reward: 19.200000, loss: 0.000137, epsilon: 0.010000, episode:  599\n",
      "frames: 1169000, reward: 18.900000, loss: 0.000296, epsilon: 0.010000, episode:  600\n",
      "frames: 1170000, reward: 18.900000, loss: 0.000272, epsilon: 0.010000, episode:  600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 1171000, reward: 19.100000, loss: 0.000200, epsilon: 0.010000, episode:  601\n",
      "frames: 1172000, reward: 19.000000, loss: 0.000116, epsilon: 0.010000, episode:  602\n",
      "frames: 1173000, reward: 19.000000, loss: 0.000070, epsilon: 0.010000, episode:  602\n",
      "frames: 1174000, reward: 19.000000, loss: 0.000643, epsilon: 0.010000, episode:  603\n",
      "frames: 1175000, reward: 19.000000, loss: 0.000544, epsilon: 0.010000, episode:  603\n",
      "frames: 1176000, reward: 19.300000, loss: 0.000332, epsilon: 0.010000, episode:  604\n",
      "frames: 1177000, reward: 19.300000, loss: 0.000099, epsilon: 0.010000, episode:  604\n",
      "frames: 1178000, reward: 19.500000, loss: 0.000175, epsilon: 0.010000, episode:  605\n",
      "frames: 1179000, reward: 19.400000, loss: 0.000107, epsilon: 0.010000, episode:  606\n",
      "frames: 1180000, reward: 19.400000, loss: 0.000260, epsilon: 0.010000, episode:  606\n",
      "frames: 1181000, reward: 19.400000, loss: 0.000817, epsilon: 0.010000, episode:  607\n",
      "frames: 1182000, reward: 19.400000, loss: 0.000109, epsilon: 0.010000, episode:  607\n",
      "frames: 1183000, reward: 19.600000, loss: 0.000225, epsilon: 0.010000, episode:  608\n",
      "frames: 1184000, reward: 19.600000, loss: 0.000078, epsilon: 0.010000, episode:  608\n",
      "frames: 1185000, reward: 19.500000, loss: 0.000097, epsilon: 0.010000, episode:  609\n",
      "frames: 1186000, reward: 20.100000, loss: 0.000096, epsilon: 0.010000, episode:  610\n",
      "frames: 1187000, reward: 20.100000, loss: 0.000123, epsilon: 0.010000, episode:  610\n",
      "frames: 1188000, reward: 20.200000, loss: 0.000098, epsilon: 0.010000, episode:  611\n",
      "frames: 1189000, reward: 20.200000, loss: 0.000093, epsilon: 0.010000, episode:  611\n",
      "frames: 1190000, reward: 20.200000, loss: 0.000087, epsilon: 0.010000, episode:  612\n",
      "frames: 1191000, reward: 20.200000, loss: 0.000202, epsilon: 0.010000, episode:  612\n",
      "frames: 1192000, reward: 20.300000, loss: 0.000102, epsilon: 0.010000, episode:  613\n",
      "frames: 1193000, reward: 20.200000, loss: 0.000127, epsilon: 0.010000, episode:  614\n",
      "frames: 1194000, reward: 20.200000, loss: 0.000055, epsilon: 0.010000, episode:  614\n",
      "frames: 1195000, reward: 20.200000, loss: 0.000073, epsilon: 0.010000, episode:  615\n",
      "frames: 1196000, reward: 20.200000, loss: 0.000148, epsilon: 0.010000, episode:  615\n",
      "frames: 1197000, reward: 20.200000, loss: 0.000141, epsilon: 0.010000, episode:  616\n",
      "frames: 1198000, reward: 20.300000, loss: 0.000278, epsilon: 0.010000, episode:  617\n",
      "frames: 1199000, reward: 20.300000, loss: 0.000136, epsilon: 0.010000, episode:  617\n",
      "frames: 1200000, reward: 20.200000, loss: 0.000185, epsilon: 0.010000, episode:  618\n",
      "frames: 1201000, reward: 20.200000, loss: 0.000275, epsilon: 0.010000, episode:  618\n",
      "frames: 1202000, reward: 20.100000, loss: 0.000118, epsilon: 0.010000, episode:  619\n",
      "frames: 1203000, reward: 20.100000, loss: 0.000083, epsilon: 0.010000, episode:  619\n",
      "frames: 1204000, reward: 20.000000, loss: 0.000092, epsilon: 0.010000, episode:  620\n",
      "frames: 1205000, reward: 20.000000, loss: 0.000094, epsilon: 0.010000, episode:  620\n",
      "frames: 1206000, reward: 19.900000, loss: 0.000138, epsilon: 0.010000, episode:  621\n",
      "frames: 1207000, reward: 19.900000, loss: 0.000051, epsilon: 0.010000, episode:  621\n",
      "frames: 1208000, reward: 20.000000, loss: 0.000186, epsilon: 0.010000, episode:  622\n",
      "frames: 1209000, reward: 19.800000, loss: 0.000552, epsilon: 0.010000, episode:  623\n",
      "frames: 1210000, reward: 19.800000, loss: 0.000090, epsilon: 0.010000, episode:  623\n",
      "frames: 1211000, reward: 19.800000, loss: 0.000344, epsilon: 0.010000, episode:  624\n",
      "frames: 1212000, reward: 19.800000, loss: 0.000136, epsilon: 0.010000, episode:  624\n",
      "frames: 1213000, reward: 19.600000, loss: 0.000363, epsilon: 0.010000, episode:  625\n",
      "frames: 1214000, reward: 19.600000, loss: 0.000064, epsilon: 0.010000, episode:  625\n",
      "frames: 1215000, reward: 19.400000, loss: 0.000373, epsilon: 0.010000, episode:  626\n",
      "frames: 1216000, reward: 19.400000, loss: 0.000201, epsilon: 0.010000, episode:  626\n",
      "frames: 1217000, reward: 19.400000, loss: 0.000244, epsilon: 0.010000, episode:  627\n",
      "frames: 1218000, reward: 19.300000, loss: 0.000146, epsilon: 0.010000, episode:  628\n",
      "frames: 1219000, reward: 19.300000, loss: 0.000403, epsilon: 0.010000, episode:  628\n",
      "frames: 1220000, reward: 19.500000, loss: 0.000070, epsilon: 0.010000, episode:  629\n",
      "frames: 1221000, reward: 19.500000, loss: 0.000123, epsilon: 0.010000, episode:  629\n",
      "frames: 1222000, reward: 19.500000, loss: 0.000102, epsilon: 0.010000, episode:  630\n",
      "frames: 1223000, reward: 19.500000, loss: 0.000155, epsilon: 0.010000, episode:  630\n",
      "frames: 1224000, reward: 19.700000, loss: 0.000143, epsilon: 0.010000, episode:  631\n",
      "frames: 1225000, reward: 19.600000, loss: 0.000229, epsilon: 0.010000, episode:  632\n",
      "frames: 1226000, reward: 19.600000, loss: 0.000072, epsilon: 0.010000, episode:  632\n",
      "frames: 1227000, reward: 19.600000, loss: 0.000068, epsilon: 0.010000, episode:  633\n",
      "frames: 1228000, reward: 19.600000, loss: 0.000119, epsilon: 0.010000, episode:  633\n",
      "frames: 1229000, reward: 19.700000, loss: 0.000198, epsilon: 0.010000, episode:  634\n",
      "frames: 1230000, reward: 19.900000, loss: 0.000136, epsilon: 0.010000, episode:  635\n",
      "frames: 1231000, reward: 19.900000, loss: 0.000255, epsilon: 0.010000, episode:  635\n",
      "frames: 1232000, reward: 20.100000, loss: 0.000196, epsilon: 0.010000, episode:  636\n",
      "frames: 1233000, reward: 20.100000, loss: 0.000215, epsilon: 0.010000, episode:  636\n",
      "frames: 1234000, reward: 20.100000, loss: 0.000515, epsilon: 0.010000, episode:  636\n",
      "frames: 1235000, reward: 18.600000, loss: 0.000145, epsilon: 0.010000, episode:  637\n",
      "frames: 1236000, reward: 18.600000, loss: 0.000231, epsilon: 0.010000, episode:  637\n",
      "frames: 1237000, reward: 18.400000, loss: 0.000441, epsilon: 0.010000, episode:  638\n",
      "frames: 1238000, reward: 18.400000, loss: 0.000184, epsilon: 0.010000, episode:  638\n",
      "frames: 1239000, reward: 18.200000, loss: 0.000245, epsilon: 0.010000, episode:  639\n",
      "frames: 1240000, reward: 18.200000, loss: 0.000101, epsilon: 0.010000, episode:  639\n",
      "frames: 1241000, reward: 17.800000, loss: 0.000228, epsilon: 0.010000, episode:  640\n",
      "frames: 1242000, reward: 17.800000, loss: 0.000257, epsilon: 0.010000, episode:  640\n",
      "frames: 1243000, reward: 17.500000, loss: 0.000152, epsilon: 0.010000, episode:  641\n",
      "frames: 1244000, reward: 17.500000, loss: 0.000137, epsilon: 0.010000, episode:  641\n",
      "frames: 1245000, reward: 17.600000, loss: 0.000136, epsilon: 0.010000, episode:  642\n",
      "frames: 1246000, reward: 17.600000, loss: 0.000124, epsilon: 0.010000, episode:  642\n",
      "frames: 1247000, reward: 17.700000, loss: 0.000233, epsilon: 0.010000, episode:  643\n",
      "frames: 1248000, reward: 17.600000, loss: 0.000094, epsilon: 0.010000, episode:  644\n",
      "frames: 1249000, reward: 17.600000, loss: 0.000180, epsilon: 0.010000, episode:  644\n",
      "frames: 1250000, reward: 17.600000, loss: 0.000461, epsilon: 0.010000, episode:  645\n",
      "frames: 1251000, reward: 17.600000, loss: 0.000201, epsilon: 0.010000, episode:  645\n",
      "frames: 1252000, reward: 17.800000, loss: 0.000083, epsilon: 0.010000, episode:  646\n",
      "frames: 1253000, reward: 19.100000, loss: 0.000403, epsilon: 0.010000, episode:  647\n",
      "frames: 1254000, reward: 19.100000, loss: 0.000083, epsilon: 0.010000, episode:  647\n",
      "frames: 1255000, reward: 19.000000, loss: 0.001649, epsilon: 0.010000, episode:  648\n",
      "frames: 1256000, reward: 19.000000, loss: 0.000815, epsilon: 0.010000, episode:  648\n",
      "frames: 1257000, reward: 18.900000, loss: 0.000507, epsilon: 0.010000, episode:  649\n",
      "frames: 1258000, reward: 18.900000, loss: 0.000105, epsilon: 0.010000, episode:  649\n",
      "frames: 1259000, reward: 19.300000, loss: 0.000564, epsilon: 0.010000, episode:  650\n",
      "frames: 1260000, reward: 19.300000, loss: 0.000426, epsilon: 0.010000, episode:  650\n",
      "frames: 1261000, reward: 19.500000, loss: 0.000207, epsilon: 0.010000, episode:  651\n",
      "frames: 1262000, reward: 19.500000, loss: 0.000139, epsilon: 0.010000, episode:  651\n",
      "frames: 1263000, reward: 19.400000, loss: 0.000162, epsilon: 0.010000, episode:  652\n",
      "frames: 1264000, reward: 19.400000, loss: 0.000063, epsilon: 0.010000, episode:  652\n",
      "frames: 1265000, reward: 19.500000, loss: 0.000092, epsilon: 0.010000, episode:  653\n",
      "frames: 1266000, reward: 19.500000, loss: 0.000192, epsilon: 0.010000, episode:  654\n",
      "frames: 1267000, reward: 19.500000, loss: 0.000369, epsilon: 0.010000, episode:  654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 1268000, reward: 19.400000, loss: 0.000769, epsilon: 0.010000, episode:  655\n",
      "frames: 1269000, reward: 19.400000, loss: 0.001011, epsilon: 0.010000, episode:  655\n",
      "frames: 1270000, reward: 19.000000, loss: 0.000064, epsilon: 0.010000, episode:  656\n",
      "frames: 1271000, reward: 19.000000, loss: 0.000289, epsilon: 0.010000, episode:  656\n",
      "frames: 1272000, reward: 18.700000, loss: 0.000682, epsilon: 0.010000, episode:  657\n",
      "frames: 1273000, reward: 18.700000, loss: 0.005846, epsilon: 0.010000, episode:  657\n",
      "frames: 1274000, reward: 19.000000, loss: 0.000205, epsilon: 0.010000, episode:  658\n",
      "frames: 1275000, reward: 19.000000, loss: 0.000183, epsilon: 0.010000, episode:  658\n",
      "frames: 1276000, reward: 19.000000, loss: 0.000222, epsilon: 0.010000, episode:  659\n",
      "frames: 1277000, reward: 19.000000, loss: 0.000247, epsilon: 0.010000, episode:  659\n",
      "frames: 1278000, reward: 19.100000, loss: 0.000133, epsilon: 0.010000, episode:  660\n",
      "frames: 1279000, reward: 19.100000, loss: 0.000132, epsilon: 0.010000, episode:  660\n",
      "frames: 1280000, reward: 19.200000, loss: 0.000304, epsilon: 0.010000, episode:  661\n",
      "frames: 1281000, reward: 19.300000, loss: 0.000239, epsilon: 0.010000, episode:  662\n",
      "frames: 1282000, reward: 19.300000, loss: 0.000095, epsilon: 0.010000, episode:  662\n",
      "frames: 1283000, reward: 19.300000, loss: 0.000086, epsilon: 0.010000, episode:  663\n",
      "frames: 1284000, reward: 19.300000, loss: 0.000164, epsilon: 0.010000, episode:  663\n",
      "frames: 1285000, reward: 19.400000, loss: 0.000048, epsilon: 0.010000, episode:  664\n",
      "frames: 1286000, reward: 19.500000, loss: 0.000070, epsilon: 0.010000, episode:  665\n",
      "frames: 1287000, reward: 19.500000, loss: 0.000072, epsilon: 0.010000, episode:  665\n",
      "frames: 1288000, reward: 19.700000, loss: 0.000116, epsilon: 0.010000, episode:  666\n",
      "frames: 1289000, reward: 19.700000, loss: 0.000243, epsilon: 0.010000, episode:  666\n",
      "frames: 1290000, reward: 19.300000, loss: 0.000106, epsilon: 0.010000, episode:  667\n",
      "frames: 1291000, reward: 19.300000, loss: 0.000336, epsilon: 0.010000, episode:  667\n",
      "frames: 1292000, reward: 19.300000, loss: 0.000428, epsilon: 0.010000, episode:  668\n",
      "frames: 1293000, reward: 19.300000, loss: 0.000075, epsilon: 0.010000, episode:  668\n",
      "frames: 1294000, reward: 19.600000, loss: 0.000067, epsilon: 0.010000, episode:  669\n",
      "frames: 1295000, reward: 19.600000, loss: 0.000118, epsilon: 0.010000, episode:  669\n",
      "frames: 1296000, reward: 19.300000, loss: 0.000048, epsilon: 0.010000, episode:  670\n",
      "frames: 1297000, reward: 19.300000, loss: 0.000741, epsilon: 0.010000, episode:  670\n",
      "frames: 1298000, reward: 19.100000, loss: 0.000121, epsilon: 0.010000, episode:  671\n",
      "frames: 1299000, reward: 19.100000, loss: 0.000073, epsilon: 0.010000, episode:  671\n",
      "frames: 1300000, reward: 18.700000, loss: 0.000070, epsilon: 0.010000, episode:  672\n",
      "frames: 1301000, reward: 18.600000, loss: 0.000499, epsilon: 0.010000, episode:  673\n",
      "frames: 1302000, reward: 18.600000, loss: 0.000223, epsilon: 0.010000, episode:  673\n",
      "frames: 1303000, reward: 18.300000, loss: 0.000152, epsilon: 0.010000, episode:  674\n",
      "frames: 1304000, reward: 18.300000, loss: 0.000078, epsilon: 0.010000, episode:  674\n",
      "frames: 1305000, reward: 18.300000, loss: 0.000149, epsilon: 0.010000, episode:  675\n",
      "frames: 1306000, reward: 18.300000, loss: 0.000114, epsilon: 0.010000, episode:  675\n",
      "frames: 1307000, reward: 18.400000, loss: 0.000666, epsilon: 0.010000, episode:  676\n",
      "frames: 1308000, reward: 19.100000, loss: 0.000488, epsilon: 0.010000, episode:  677\n",
      "frames: 1309000, reward: 19.100000, loss: 0.000106, epsilon: 0.010000, episode:  677\n",
      "frames: 1310000, reward: 19.200000, loss: 0.000208, epsilon: 0.010000, episode:  678\n",
      "frames: 1311000, reward: 19.200000, loss: 0.000120, epsilon: 0.010000, episode:  678\n",
      "frames: 1312000, reward: 19.000000, loss: 0.000071, epsilon: 0.010000, episode:  679\n",
      "frames: 1313000, reward: 19.000000, loss: 0.000100, epsilon: 0.010000, episode:  679\n",
      "frames: 1314000, reward: 19.200000, loss: 0.000115, epsilon: 0.010000, episode:  680\n",
      "frames: 1315000, reward: 19.200000, loss: 0.000064, epsilon: 0.010000, episode:  680\n",
      "frames: 1316000, reward: 19.100000, loss: 0.000088, epsilon: 0.010000, episode:  681\n",
      "frames: 1317000, reward: 19.500000, loss: 0.000203, epsilon: 0.010000, episode:  682\n",
      "frames: 1318000, reward: 19.500000, loss: 0.000214, epsilon: 0.010000, episode:  682\n",
      "frames: 1319000, reward: 19.500000, loss: 0.000088, epsilon: 0.010000, episode:  683\n",
      "frames: 1320000, reward: 19.500000, loss: 0.000104, epsilon: 0.010000, episode:  683\n",
      "frames: 1321000, reward: 19.600000, loss: 0.000082, epsilon: 0.010000, episode:  684\n",
      "frames: 1322000, reward: 19.600000, loss: 0.000130, epsilon: 0.010000, episode:  684\n",
      "frames: 1323000, reward: 19.500000, loss: 0.000079, epsilon: 0.010000, episode:  685\n",
      "frames: 1324000, reward: 19.500000, loss: 0.000070, epsilon: 0.010000, episode:  685\n",
      "frames: 1325000, reward: 19.400000, loss: 0.000043, epsilon: 0.010000, episode:  686\n",
      "frames: 1326000, reward: 19.600000, loss: 0.000114, epsilon: 0.010000, episode:  687\n",
      "frames: 1327000, reward: 19.600000, loss: 0.000090, epsilon: 0.010000, episode:  687\n",
      "frames: 1328000, reward: 19.500000, loss: 0.000203, epsilon: 0.010000, episode:  688\n",
      "frames: 1329000, reward: 19.500000, loss: 0.000095, epsilon: 0.010000, episode:  688\n",
      "frames: 1330000, reward: 19.100000, loss: 0.000205, epsilon: 0.010000, episode:  689\n",
      "frames: 1331000, reward: 19.100000, loss: 0.000073, epsilon: 0.010000, episode:  689\n",
      "frames: 1332000, reward: 19.100000, loss: 0.000082, epsilon: 0.010000, episode:  690\n",
      "frames: 1333000, reward: 19.100000, loss: 0.000058, epsilon: 0.010000, episode:  690\n",
      "frames: 1334000, reward: 19.300000, loss: 0.000098, epsilon: 0.010000, episode:  691\n",
      "frames: 1335000, reward: 19.300000, loss: 0.000149, epsilon: 0.010000, episode:  691\n",
      "frames: 1336000, reward: 19.000000, loss: 0.000166, epsilon: 0.010000, episode:  692\n",
      "frames: 1337000, reward: 19.000000, loss: 0.000211, epsilon: 0.010000, episode:  692\n",
      "frames: 1338000, reward: 19.000000, loss: 0.000155, epsilon: 0.010000, episode:  693\n",
      "frames: 1339000, reward: 19.000000, loss: 0.000114, epsilon: 0.010000, episode:  693\n",
      "frames: 1340000, reward: 19.000000, loss: 0.000416, epsilon: 0.010000, episode:  694\n",
      "frames: 1341000, reward: 19.100000, loss: 0.000638, epsilon: 0.010000, episode:  695\n",
      "frames: 1342000, reward: 19.100000, loss: 0.000289, epsilon: 0.010000, episode:  695\n",
      "frames: 1343000, reward: 19.000000, loss: 0.000145, epsilon: 0.010000, episode:  696\n",
      "frames: 1344000, reward: 19.000000, loss: 0.000134, epsilon: 0.010000, episode:  696\n",
      "frames: 1345000, reward: 19.000000, loss: 0.016870, epsilon: 0.010000, episode:  697\n",
      "frames: 1346000, reward: 19.000000, loss: 0.000068, epsilon: 0.010000, episode:  697\n",
      "frames: 1347000, reward: 19.100000, loss: 0.000052, epsilon: 0.010000, episode:  698\n",
      "frames: 1348000, reward: 19.100000, loss: 0.000093, epsilon: 0.010000, episode:  698\n",
      "frames: 1349000, reward: 19.600000, loss: 0.000088, epsilon: 0.010000, episode:  699\n",
      "frames: 1350000, reward: 19.700000, loss: 0.000242, epsilon: 0.010000, episode:  700\n",
      "frames: 1351000, reward: 19.700000, loss: 0.000139, epsilon: 0.010000, episode:  700\n",
      "frames: 1352000, reward: 19.800000, loss: 0.000075, epsilon: 0.010000, episode:  701\n",
      "frames: 1353000, reward: 19.800000, loss: 0.000084, epsilon: 0.010000, episode:  701\n",
      "frames: 1354000, reward: 19.900000, loss: 0.000136, epsilon: 0.010000, episode:  702\n",
      "frames: 1355000, reward: 20.000000, loss: 0.000141, epsilon: 0.010000, episode:  703\n",
      "frames: 1356000, reward: 20.000000, loss: 0.000056, epsilon: 0.010000, episode:  703\n",
      "frames: 1357000, reward: 20.100000, loss: 0.000058, epsilon: 0.010000, episode:  704\n",
      "frames: 1358000, reward: 20.100000, loss: 0.000106, epsilon: 0.010000, episode:  704\n",
      "frames: 1359000, reward: 20.100000, loss: 0.000074, epsilon: 0.010000, episode:  705\n",
      "frames: 1360000, reward: 20.400000, loss: 0.000124, epsilon: 0.010000, episode:  706\n",
      "frames: 1361000, reward: 20.400000, loss: 0.000242, epsilon: 0.010000, episode:  706\n",
      "frames: 1362000, reward: 20.300000, loss: 0.000206, epsilon: 0.010000, episode:  707\n",
      "frames: 1363000, reward: 20.300000, loss: 0.000065, epsilon: 0.010000, episode:  707\n",
      "frames: 1364000, reward: 20.100000, loss: 0.000078, epsilon: 0.010000, episode:  708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames: 1365000, reward: 20.100000, loss: 0.000084, epsilon: 0.010000, episode:  708\n",
      "frames: 1366000, reward: 20.200000, loss: 0.000090, epsilon: 0.010000, episode:  709\n",
      "frames: 1367000, reward: 20.200000, loss: 0.000261, epsilon: 0.010000, episode:  709\n",
      "frames: 1368000, reward: 19.900000, loss: 0.000272, epsilon: 0.010000, episode:  710\n",
      "frames: 1369000, reward: 19.900000, loss: 0.000184, epsilon: 0.010000, episode:  711\n",
      "frames: 1370000, reward: 19.900000, loss: 0.000136, epsilon: 0.010000, episode:  711\n",
      "frames: 1371000, reward: 20.000000, loss: 0.000136, epsilon: 0.010000, episode:  712\n",
      "frames: 1372000, reward: 20.000000, loss: 0.000890, epsilon: 0.010000, episode:  712\n",
      "frames: 1373000, reward: 19.600000, loss: 0.000093, epsilon: 0.010000, episode:  713\n",
      "frames: 1374000, reward: 19.600000, loss: 0.000232, epsilon: 0.010000, episode:  713\n",
      "frames: 1375000, reward: 19.700000, loss: 0.000081, epsilon: 0.010000, episode:  714\n",
      "frames: 1376000, reward: 19.700000, loss: 0.000094, epsilon: 0.010000, episode:  714\n",
      "frames: 1377000, reward: 19.500000, loss: 0.000326, epsilon: 0.010000, episode:  715\n",
      "frames: 1378000, reward: 19.500000, loss: 0.000119, epsilon: 0.010000, episode:  715\n",
      "frames: 1379000, reward: 19.400000, loss: 0.000123, epsilon: 0.010000, episode:  716\n",
      "frames: 1380000, reward: 19.400000, loss: 0.000175, epsilon: 0.010000, episode:  716\n",
      "frames: 1381000, reward: 18.900000, loss: 0.000525, epsilon: 0.010000, episode:  717\n",
      "frames: 1382000, reward: 18.900000, loss: 0.000177, epsilon: 0.010000, episode:  717\n",
      "frames: 1383000, reward: 19.200000, loss: 0.000248, epsilon: 0.010000, episode:  718\n",
      "frames: 1384000, reward: 19.200000, loss: 0.000356, epsilon: 0.010000, episode:  719\n",
      "frames: 1385000, reward: 19.200000, loss: 0.000074, epsilon: 0.010000, episode:  719\n",
      "frames: 1386000, reward: 19.500000, loss: 0.000104, epsilon: 0.010000, episode:  720\n",
      "frames: 1387000, reward: 19.500000, loss: 0.000410, epsilon: 0.010000, episode:  720\n",
      "frames: 1388000, reward: 19.600000, loss: 0.000194, epsilon: 0.010000, episode:  721\n",
      "frames: 1389000, reward: 19.700000, loss: 0.000192, epsilon: 0.010000, episode:  722\n",
      "frames: 1390000, reward: 19.700000, loss: 0.000742, epsilon: 0.010000, episode:  722\n",
      "frames: 1391000, reward: 19.700000, loss: 0.000118, epsilon: 0.010000, episode:  722\n",
      "frames: 1392000, reward: 19.100000, loss: 0.000414, epsilon: 0.010000, episode:  723\n",
      "frames: 1393000, reward: 19.100000, loss: 0.000190, epsilon: 0.010000, episode:  723\n",
      "frames: 1394000, reward: 18.700000, loss: 0.000203, epsilon: 0.010000, episode:  724\n",
      "frames: 1395000, reward: 18.700000, loss: 0.000183, epsilon: 0.010000, episode:  724\n",
      "frames: 1396000, reward: 18.700000, loss: 0.000961, epsilon: 0.010000, episode:  725\n",
      "frames: 1397000, reward: 18.700000, loss: 0.001612, epsilon: 0.010000, episode:  725\n",
      "frames: 1398000, reward: 18.700000, loss: 0.001127, epsilon: 0.010000, episode:  725\n",
      "frames: 1399000, reward: 17.400000, loss: 0.000242, epsilon: 0.010000, episode:  726\n",
      "frames: 1400000, reward: 17.400000, loss: 0.998195, epsilon: 0.010000, episode:  726\n",
      "frames: 1401000, reward: 18.000000, loss: 0.000432, epsilon: 0.010000, episode:  727\n",
      "frames: 1402000, reward: 18.000000, loss: 0.000255, epsilon: 0.010000, episode:  727\n",
      "frames: 1403000, reward: 17.300000, loss: 0.003419, epsilon: 0.010000, episode:  728\n",
      "frames: 1404000, reward: 17.300000, loss: 0.001425, epsilon: 0.010000, episode:  728\n",
      "frames: 1405000, reward: 16.600000, loss: 0.000648, epsilon: 0.010000, episode:  729\n",
      "frames: 1406000, reward: 16.600000, loss: 0.000584, epsilon: 0.010000, episode:  729\n",
      "frames: 1407000, reward: 16.400000, loss: 0.000296, epsilon: 0.010000, episode:  730\n",
      "frames: 1408000, reward: 16.400000, loss: 0.000321, epsilon: 0.010000, episode:  730\n",
      "frames: 1409000, reward: 16.400000, loss: 0.001111, epsilon: 0.010000, episode:  730\n",
      "frames: 1410000, reward: 15.400000, loss: 0.000276, epsilon: 0.010000, episode:  731\n",
      "frames: 1411000, reward: 15.400000, loss: 0.000388, epsilon: 0.010000, episode:  731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1ae97a5282f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mnext_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\baselines\\common\\atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\baselines\\common\\atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, ac)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mEpisodicLifeEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\baselines\\common\\atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\softwares\\ANACONDA\\lib\\site-packages\\baselines\\common\\atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "    \n",
    "# Training DQN in PongNoFrameskip-v4 \n",
    "env = make_atari('PongNoFrameskip-v4')\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True)\n",
    "\n",
    "gamma = 0.99\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.01\n",
    "eps_decay = 30000\n",
    "frames = 2000000\n",
    "USE_CUDA = True\n",
    "learning_rate = 2e-4\n",
    "max_buff = 100000\n",
    "update_tar_interval = 1000\n",
    "batch_size = 32\n",
    "print_interval = 1000\n",
    "log_interval = 1000\n",
    "learning_start = 10000\n",
    "win_reward = 18     # Pong-v4\n",
    "win_break = True\n",
    "\n",
    "action_space = env.action_space\n",
    "action_dim = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "state_channel = env.observation_space.shape[2]\n",
    "agent = DQNAgent(in_channels = state_channel, action_space= action_space, USE_CUDA = USE_CUDA, lr = learning_rate)\n",
    "\n",
    "frame = env.reset()\n",
    "\n",
    "episode_reward = 0\n",
    "all_rewards = []\n",
    "losses = []\n",
    "episode_num = 0\n",
    "is_win = False\n",
    "# tensorboard\n",
    "summary_writer = SummaryWriter(log_dir = \"DQN_stackframe\", comment= \"good_makeatari\")\n",
    "\n",
    "# e-greedy decay\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_min + (epsilon_max - epsilon_min) * math.exp(\n",
    "            -1. * frame_idx / eps_decay)\n",
    "# plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
    "\n",
    "for i in range(frames):\n",
    "    epsilon = epsilon_by_frame(i)\n",
    "    state_tensor = agent.observe(frame)\n",
    "    action = agent.act(state_tensor, epsilon)\n",
    "    \n",
    "    next_frame, reward, done, _ = env.step(action)\n",
    "    \n",
    "    episode_reward += reward\n",
    "    agent.memory_buffer.push(frame, action, reward, next_frame, done)\n",
    "    frame = next_frame\n",
    "    \n",
    "    loss = 0\n",
    "    if agent.memory_buffer.size() >= learning_start:\n",
    "        loss = agent.learn_from_experience(batch_size)\n",
    "        losses.append(loss)\n",
    "\n",
    "    if i % print_interval == 0:\n",
    "        print(\"frames: %5d, reward: %5f, loss: %4f, epsilon: %5f, episode: %4d\" % (i, np.mean(all_rewards[-10:]), loss, epsilon, episode_num))\n",
    "        summary_writer.add_scalar(\"Temporal Difference Loss\", loss, i)\n",
    "        summary_writer.add_scalar(\"Mean Reward\", np.mean(all_rewards[-10:]), i)\n",
    "        summary_writer.add_scalar(\"Epsilon\", epsilon, i)\n",
    "        \n",
    "    if i % update_tar_interval == 0:\n",
    "        agent.DQN_target.load_state_dict(agent.DQN.state_dict())\n",
    "    \n",
    "    if done:\n",
    "        \n",
    "        frame = env.reset()\n",
    "        \n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        episode_num += 1\n",
    "        avg_reward = float(np.mean(all_rewards[-100:]))\n",
    "\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "plot_training(i, all_rewards, losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
